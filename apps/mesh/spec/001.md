# Declare and Compose Context: A New Paradigm for MCP-native Software Engineering

> We propose a secure, web-based MCP admin that centralizes **Context Management** for AI applications across teams and organizations with integrated observability and cost control.

## Introduction

The advent of Large Language Models (LLMs) has fundamentally changed how we interact with software. Instead of searching on Google, people now converse with AI assistants. This evolution took another leap when LLMs gained the ability to execute software directly through "tools"—functions that take inputs and return outputs.

Initially, these tools ran in the same runtime environment as the LLM. However, the introduction of the Model Context Protocol (MCP) changed this paradigm. MCP provides a standardized way for AI systems to discover and invoke tools across process boundaries, enabling any service to expose its capabilities to AI agents in a consistent manner.

### The Problem

This new paradigm introduces significant challenges for teams and organizations:

**Connection Management**: Users must manage connections to numerous MCP services, each with its own authentication, payment, and configuration requirements.

**Access Control & Privacy**: There's no way to share MCP access within a team without sharing personal credentials. For example, if your team needs to send emails via an MCP tool, someone must connect their personal Gmail account for everyone to use—creating security risks and privacy concerns.

**Tool Orchestration**: MCP services operate in isolation, with no standard way to compose tools from multiple services or manage dependencies between them.

### Our Solution: MCP Mesh

We're building the first open-source MCP Mesh — a unified platform that solves these challenges by:

1. **Centralizing MCP connections**: Connect all your MCP services in one place with unified authentication

2. **Fine-grained access control**: Create teams and members with precise permissions:
   - Grant specific users access to specific MCP services
   - Share a single connection across your team without exposing credentials
   - Audit who accessed which tools and when
   - Revoke access instantly without changing passwords

3. **Enabling tool composition**: Allow MCP services to depend on each other, eliminating redundant account connections

4. **Providing zero-config deployment**: Run the MCP Mesh locally without complex setup

5. **Being MCP-native**: The Mesh itself exposes an MCP interface, allowing it to be used by any MCP-compatible client

### Apps: Extending MCP

In MCP Mesh, we use "App" and "MCP service" interchangeably. Apps are a superset of MCP — we extend the protocol to support additional features such as:

- **Native multi-tenancy**: Apps can expose configuration schemas via tool calls, which the Mesh renders as user-friendly forms
- **Tool dependencies**: Apps can declare dependencies on other apps' tools
- **Unified discovery**: Browse and install apps from a centralized marketplace
- **Team-based ACLs**: Built-in support for team hierarchies, roles, and fine-grained permissions

The result is a composable, secure, open-source infrastructure layer for the AI-native software era.

---

## Key Architectural Decisions

1. **Multi-Level Namespacing**: Operations can be scoped at organization or project level:
   - **Organization-scoped**: MCPs shared across all projects (when `projectId` is null)
   - **Project-scoped**: MCPs isolated to a single project (when `projectId` is set)
   - The database connection itself represents the organization boundary (cluster-level)
   - Projects provide isolation for policies, teams, and audit logs (namespace-level)

2. **MCP-Native API**: Instead of REST, the Mesh uses MCP tools for all management operations. This makes the Mesh itself an MCP service that can be accessed programmatically or via AI agents.

3. **Minimal Configuration**: Only one environment variable (`DATABASE_URL`). All authentication configuration is file-based (`auth-config.json`).

4. **JWT with Audience Claims**: Tokens include an `aud` claim with stable identifiers, enabling strong isolation and preventing cross-scope token reuse.

5. **Policy-Based Access Control**: Fine-grained permissions via Statements → Policies → Roles hierarchy, inspired by AWS IAM.

6. **Zero-Config SQLite**: Uses Bun's native SQLite by default. No database setup required. Upgrade to PostgreSQL when needed.

7. **Credential Isolation**: Original service tokens never leave the Mesh. The proxy replaces Mesh tokens with actual credentials at request time.

8. **Simple URL Structure**:
   - `/mcp/tools/:toolName` - Tool execution (connection management, etc.)
   - `/mcp/:connectionId` - MCP proxy to any connection (globally unique UUIDs)

---

## Implementation Architecture

### Code Organization

The codebase is organized to maintain clear separation of concerns between the HTTP API layer and the business logic (tools).

```
apps/mesh/
├── src/
│   ├── api/
│   │   ├── index.ts                 # Hono app initialization
│   │   ├── middlewares/
│   │   │   ├── inject-context.ts    # Middleware that injects MeshContext into requests
│   │   │   ├── auth.ts              # Authentication middleware
│   │   │   ├── mcp-auth.ts          # MCP OAuth 2.1 authentication middleware (Bearer tokens)
│   │   │   ├── project-scope.ts     # Project validation middleware
│   │   │   └── authorization.ts     # Authorization verification middleware
│   │   └── routes/
│   │       ├── tools.ts             # /mcp/tools/:toolName routes
│   │       └── proxy.ts             # /mcp/:connectionId proxy routes
│   │
│   ├── tools/
│   │   ├── project/
│   │   │   ├── create.ts            # PROJECT_CREATE
│   │   │   ├── list.ts              # PROJECT_LIST
│   │   │   ├── get.ts               # PROJECT_GET
│   │   │   ├── update.ts            # PROJECT_UPDATE
│   │   │   └── delete.ts            # PROJECT_DELETE
│   │   ├── connection/
│   │   │   ├── create.ts            # CONNECTION_CREATE
│   │   │   ├── list.ts              # CONNECTION_LIST
│   │   │   └── ...
│   │   ├── policy/
│   │   ├── role/
│   │   ├── token/
│   │   └── audit/
│   │
│   ├── core/
│   │   ├── mesh-context.ts          # MeshContext interface definition
│   │   ├── context-factory.ts       # Factory function to create MeshContext
│   │   ├── access-control.ts        # Access control helper for authorization
│   │   ├── define-tool.ts           # defineTool function for declarative tool definitions
│   │   ├── bindings.ts              # MCP binding definitions (CHAT, EMAIL, STORAGE, etc.)
│   │   └── binding-detector.ts      # Automatic binding detection for connections
│   │
│   ├── storage/
│   │   ├── types.ts                 # Kysely database type definitions
│   │   ├── connection.ts            # ConnectionStorage (uses Kysely)
│   │   ├── policy.ts                # PolicyStorage (uses Kysely)
│   │   ├── project.ts               # ProjectStorage (uses Kysely)
│   │   ├── role.ts                  # RoleStorage (uses Kysely)
│   │   ├── token.ts                 # AccessTokenStorage (uses Kysely)
│   │   ├── token-revocation.ts      # TokenRevocationStorage (uses Kysely)
│   │   ├── team.ts                  # TeamStorage (uses Kysely)
│   │   ├── audit-log.ts             # AuditLogStorage (uses Kysely)
│   │   ├── oauth-client.ts          # OAuth client storage (Dynamic Client Registration)
│   │   ├── oauth-code.ts            # Authorization code storage (PKCE)
│   │   ├── oauth-refresh-token.ts   # Refresh token storage (for Mesh-issued tokens)
│   │   └── downstream-token.ts      # Downstream MCP token cache
│   │
│   ├── auth/
│   │   ├── index.ts                 # Better Auth configuration with JWT + Admin plugins
│   │   ├── mcp-oauth-metadata.ts    # MCP OAuth metadata endpoints (RFC9728, RFC8414)
│   │   ├── oauth-register.ts        # Dynamic Client Registration (RFC7591)
│   │   ├── oauth-authorize.ts       # Authorization endpoint (OAuth 2.1)
│   │   ├── oauth-token.ts           # Token endpoint (OAuth 2.1)
│   │   ├── oauth-introspect.ts      # Token introspection endpoint
│   │   └── token-introspection.ts   # Helper for validating downstream MCP tokens
│   │
│   ├── observability/
│   │   └── index.ts                 # OpenTelemetry setup (tracer, meter, metrics)
│   │
│   └── encryption/
│       └── credential-vault.ts      # Credential encryption/decryption
```

### Architecture Principles

#### 1. Separation of Concerns

**API Layer Responsibilities:**

- HTTP request/response handling
- Middleware orchestration
- Context creation and injection
- Error handling and formatting
- Route definitions

**Tool Layer Responsibilities:**

- Business logic execution
- Data validation
- Authorization checks
- Storage operations via context interfaces

**Tools must NOT:**

- Access HTTP request/response objects directly
- Know about Hono or any HTTP framework details
- Import database drivers directly
- Handle HTTP status codes

#### 2. MeshContext: The Core Abstraction

Every tool receives a `MeshContext` that provides access to all necessary services through well-defined interfaces:

```typescript
// core/mesh-context.ts
interface MeshContext {
  // Authentication (via Better Auth API Key)
  auth: {
    user?: User;
    apiKey?: {
      id: string;
      name: string;
      userId: string;
      permissions: Record<string, string[]>; // Better Auth permission model
      metadata?: Record<string, any>;
      remaining?: number;
      expiresAt?: Date;
    };
  };
  
  // Project scope (for namespace-scoped endpoints)
  // If undefined, context is organization-scoped (cluster-level)
  project?: {
    id: string;
    slug: string;
    ownerId: string;
  };
  
  // Storage interfaces (database = workspace boundary)
  storage: {
    projects: ProjectStorage;
    connections: ConnectionStorage;
    policies: PolicyStorage;
    roles: RoleStorage;
    tokens: AccessTokenStorage;
    tokenRevocations: TokenRevocationStorage;
    teams: TeamStorage;
    auditLogs: AuditLogStorage;
  };
  
  // Security services
  vault: CredentialVault;      // For encrypting connection credentials
  auth: BetterAuthInstance;    // Better Auth instance for API key operations
  
  // Access control (for authorization using Better Auth permissions)
  access: AccessControl;
  
  // Database (Kysely instance for direct queries when needed, e.g., OAuth tables)
  db: Kysely<Database>;
  
  // Current tool being executed (set by defineTool wrapper)
  toolName?: string;
  
  // Observability (OpenTelemetry)
  tracer: Tracer;           // For distributed tracing
  meter: Meter;             // For metrics collection
  
  // Base URL (derived from request, used for OAuth callbacks, metadata URLs, etc.)
  baseUrl: string;          // e.g., "https://mesh.example.com" or "http://localhost:3000"
  
  // Request metadata (non-HTTP specific)
  metadata: {
    requestId: string;
    timestamp: Date;
    userAgent?: string;
    ipAddress?: string;
  };
}
```

#### 3. Tool Definition Pattern

Tools are defined using the `defineTool` function with Zod schemas for type-safe validation:

```typescript
// core/define-tool.ts
import { z } from 'zod';
import type { MeshContext } from './mesh-context';

export interface ToolDefinition<TInput extends z.ZodType, TOutput extends z.ZodType> {
  name: string;
  description: string;
  inputSchema: TInput;
  outputSchema?: TOutput;
  handler: (input: z.infer<TInput>, ctx: MeshContext) => Promise<z.infer<TOutput>>;
}

export function defineTool<TInput extends z.ZodType, TOutput extends z.ZodType>(
  definition: ToolDefinition<TInput, TOutput>
) {
  return {
    ...definition,
    
    // Wrapped handler that adds context, authorization, validation, and logging
    execute: async (input: z.infer<TInput>, ctx: MeshContext): Promise<z.infer<TOutput>> => {
      // Set tool name in context
      ctx.toolName = definition.name;
      
      // MCP already validated input/output against JSON Schema derived from Zod
      // No need to parse again - just execute the handler
      const output = await definition.handler(input, ctx);
      
      // Automatic audit logging
      await ctx.storage.auditLogs.log({
        projectId: ctx.project?.id,
        userId: ctx.auth.user?.id,
        toolName: definition.name,
        allowed: ctx.access.granted(),
        timestamp: new Date(),
        requestMetadata: { input },
      });
      
      return output;
    },
  };
}
```

**Example Tool Definition:**

```typescript
// tools/connection/create.ts
import { z } from 'zod';
import { defineTool } from '../../core/define-tool';

const connectionSchema = z.discriminatedUnion('type', [
  z.object({
    type: z.literal('HTTP'),
    url: z.string().url(),
    token: z.string().optional(),
  }),
  z.object({
    type: z.literal('SSE'),
    url: z.string().url(),
    token: z.string().optional(),
    headers: z.record(z.string()).optional(),
  }),
  z.object({
    type: z.literal('Websocket'),
    url: z.string().url(),
    token: z.string().optional(),
  }),
]);

export const CONNECTION_CREATE = defineTool({
  name: 'CONNECTION_CREATE',
  description: 'Create a new MCP connection in the project',
  
  // Zod schema for type-safe validation
  inputSchema: z.object({
    name: z.string().min(1).max(255),
    description: z.string().optional(),
    icon: z.string().optional(),
    projectId: z.string().nullable().optional(), // null = organization-scoped
    connection: connectionSchema,
    metadata: z.record(z.any()).optional(),
  }),
  
  outputSchema: z.object({
    id: z.string(),
    name: z.string(),
    scope: z.enum(['workspace', 'project']),
    status: z.enum(['active', 'inactive', 'error']),
  }),
  
  handler: async (input, ctx) => {
    // Check authorization (checks current tool name by default)
    await ctx.access.check();
    
    // Business logic
    const connection = await ctx.storage.connections.create({
      projectId: ctx.project?.id ?? null, // null = organization-scoped
      ...input,
      createdById: ctx.auth.user!.id,
    });
    
    return {
      id: connection.id,
      name: connection.name,
      scope: connection.projectId ? 'project' : 'workspace',
      status: connection.status,
    };
  },
});
```

**Benefits of `defineTool`:**

1. **Type-Safe**: Zod schemas provide compile-time and runtime type safety
2. **Automatic Validation**: Input and output are validated automatically
3. **Declarative**: Schema and handler are co-located
4. **Automatic Logging**: Audit logs are automatically created
5. **Self-Documenting**: Zod schemas serve as documentation and can generate JSON Schema for MCP
6. **Testable**: Easy to mock and test handlers
7. **MCP Compatible**: Tool definitions can be exposed directly via MCP protocol

#### 4. Authorization Pattern

Tools must explicitly authorize operations using the improved access control API. The authorization flow follows this pattern:

**Step 1: Middleware Injects Context**

```typescript
// api/middlewares/inject-context.ts
app.use('*', async (c, next) => {
  const ctx: MeshContext = await createMeshContext(c);
  c.set('meshContext', ctx);
  await next();
});
```

**Step 2: Tool Pipeline Checks Policies (Non-Blocking)**

```typescript
// api/middlewares/authorization.ts
app.use('/mcp/tools/*', async (c, next) => {
  const ctx = c.get('meshContext');
  const toolName = extractToolName(c.req.path);
  
  // Check if user has policies that MIGHT allow this tool
  // This is a pre-check, not enforcement
  const hasRelevantPolicies = await ctx.storage.policies.userHasPolicies(
    ctx.auth.user?.id,
    ctx.project?.id
  );
  
  if (!hasRelevantPolicies) {
    throw new ForbiddenError('No policies found for user');
  }
  
  // Continue - tool will do fine-grained check
  await next();
});
```

**Step 3: Tool Explicitly Grants Access**

```typescript
// tools/connection/create.ts
import { defineTool } from '../../core/define-tool';

const connectionSchema = z.discriminatedUnion('type', [
  z.object({
    type: z.literal('HTTP'),
    url: z.string().url(),
    token: z.string().optional(),
  }),
  z.object({
    type: z.literal('SSE'),
    url: z.string().url(),
    token: z.string().optional(),
    headers: z.record(z.string()).optional(),
  }),
  z.object({
    type: z.literal('Websocket'),
    url: z.string().url(),
    token: z.string().optional(),
  }),
]);

export const CONNECTION_CREATE = defineTool({
  name: 'CONNECTION_CREATE',
  description: 'Create a new MCP connection in the project',
  
  // Zod schema for type-safe validation
  inputSchema: z.object({
    name: z.string().min(1).max(255),
    description: z.string().optional(),
    icon: z.string().optional(),
    projectId: z.string().nullable().optional(), // null = organization-scoped
    connection: connectionSchema,
    metadata: z.record(z.any()).optional(),
    discoverOAuth: z.boolean().optional().default(true), // Auto-discover OAuth config
  }),
  
  handler: async (input, ctx) => {
    // Check authorization (checks current tool name by default)
    await ctx.access.check();
    
    // Discover OAuth configuration if enabled (happens only once at creation time)
    let oauthConfig: OAuthConfig | undefined;
    if (input.discoverOAuth) {
      oauthConfig = await discoverDownstreamOAuth(input.connection.url);
      
      if (oauthConfig) {
        // Encrypt client secret if present
        if (oauthConfig.clientSecret) {
          oauthConfig.clientSecret = await ctx.vault.encrypt(oauthConfig.clientSecret);
        }
      }
    }
    
    // Create connection with OAuth config
    const connection = await ctx.storage.connections.create({
      projectId: ctx.project?.id ?? null, // null = organization-scoped
      ...input,
      oauthConfig, // Store discovered OAuth configuration
      createdById: ctx.auth.user!.id,
    });
    
    return {
      id: connection.id,
      name: connection.name,
      scope: connection.projectId ? 'project' : 'organization',
      status: connection.status,
      hasOAuth: !!oauthConfig, // Indicates if downstream MCP supports OAuth
    };
  },
});
```

**Access Control API:**

The `ctx.access` object provides a clean API for authorization checks using Better Auth's permission model:

```typescript
// core/access-control.ts
import type { BetterAuthInstance } from 'better-auth';
import type { Permission } from '../storage/types';

/**
 * AccessControl using Better Auth's permission system
 * Works with both:
 * - Admin plugin (role-based permissions): https://www.better-auth.com/docs/plugins/admin#access-control
 * - API Key plugin (key-based permissions): https://www.better-auth.com/docs/plugins/api-key#permissions
 * 
 * Both plugins use the same permission format: { [resource]: [actions...] }
 */
export class AccessControl {
  private _granted: boolean = false;
  
  constructor(
    private auth: BetterAuthInstance,
    private userId?: string,
    private toolName?: string,
    private permissions?: Permission,  // From API key
    private role?: string,             // From user session
    private connectionId?: string      // For connection-specific checks
  ) {}
  
  /**
   * Grant access unconditionally
   * Use this for manual overrides, admin actions, or after custom validation
   */
  grant(): void {
    this._granted = true;
  }
  
  /**
   * Check permissions and grant access if allowed
   * Uses Better Auth's permission system for both role-based and API key-based auth
   * 
   * @param resources - Optional resources to check (OR logic)
   *                    Format: connection IDs (conn_<UUID>) or tool names
   * If omitted, checks the current tool name
   * 
   * @throws ForbiddenError if access is denied
   * 
   * @example
   * await ctx.access.check(); // Check current tool
   * await ctx.access.check('conn_<UUID>'); // Check specific connection access
   * await ctx.access.check('SEND_MESSAGE'); // Check specific tool
   * await ctx.access.check('TOOL1', 'TOOL2'); // Check if user has access to TOOL1 OR TOOL2
   */
  async check(...resources: string[]): Promise<void> {
    // If already granted, no need to check again
    if (this._granted) {
      return;
    }
    
    // Determine what to check
    const resourcesToCheck = resources.length > 0 
      ? resources 
      : this.toolName ? [this.toolName] : [];
    
    if (resourcesToCheck.length === 0) {
      throw new ForbiddenError('No resources specified for access check');
    }
    
    // Try each resource - if ANY succeeds, grant access (OR logic)
    for (const resource of resourcesToCheck) {
      const hasAccess = await this.checkResource(resource);
      if (hasAccess) {
        this.grant();
        return;
      }
    }
    
    // No permission found for any of the requested resources
    throw new ForbiddenError(
      `Access denied to: ${resourcesToCheck.join(', ')}`
    );
  }
  
  /**
   * Check if user has permission to access a specific resource
   * Uses Better Auth's hasPermission API
   */
  private async checkResource(resource: string): Promise<boolean> {
    // If no user or permissions, deny access
    if (!this.userId && !this.permissions) {
      return false;
    }
    
    // Build permission object for Better Auth
    // Format: { [resource]: [actions] }
    // We check if the resource grants ANY action (wildcard check)
    const permissionToCheck: Permission = {
      [resource]: ['*'], // Check for any action
    };
    
    // If checking a specific connection, also check that connection ID
    if (this.connectionId) {
      permissionToCheck[this.connectionId] = [resource];
    }
    
    try {
      // Use Better Auth's permission checking
      // https://www.better-auth.com/docs/plugins/admin#access-control
      const result = await this.auth.api.userHasPermission({
        body: {
          userId: this.userId!,
          role: this.role,           // For role-based permissions (admin plugin)
          permissions: this.permissions, // For API key permissions
          permission: permissionToCheck,
        },
      });
      
      return result.data?.has === true;
    } catch (error) {
      // If Better Auth check fails, fall back to manual permission check
      return this.manualPermissionCheck(resource);
    }
  }
  
  /**
   * Fallback manual permission check
   * Used when Better Auth API is unavailable or for API key-only auth
   */
  private manualPermissionCheck(resource: string): boolean {
    if (!this.permissions || Object.keys(this.permissions).length === 0) {
      return false;
    }
    
    // Check if permission grants access to this resource
    for (const [key, actions] of Object.entries(this.permissions)) {
      // If checking a specific connection, skip others
      if (this.connectionId && key !== this.connectionId) {
        continue;
      }
      
      // Check if resource matches or has wildcard
      if (key === resource || actions.includes(resource) || actions.includes('*')) {
        return true;
      }
    }
    
    return false;
  }
  
  /**
   * Check if access was granted
   */
  granted(): boolean {
    return this._granted;
  }
}
```

**Usage Examples:**

```typescript
// Example 1: Check access to current tool
export const CREATE_CONNECTION = defineTool({
  name: 'CREATE_CONNECTION',
  handler: async (input, ctx) => {
    // Check if user has permission (checks current tool name)
    await ctx.access.check(); // Checks CREATE_CONNECTION
    
    // Business logic...
  },
});

// Example 2: Check access to delegated tools
export const BULK_CREATE_CONNECTIONS = defineTool({
  name: 'BULK_CREATE_CONNECTIONS',
  handler: async (input, ctx) => {
    // First check access to this tool
    await ctx.access.check();
    
    // Check if user has CREATE_CONNECTION permission before delegating
    await ctx.access.check('CREATE_CONNECTION');
    
    // Now we can call CREATE_CONNECTION for each item...
  },
});

// Example 3: Check access to ANY of multiple tools (OR logic)
export const SYNC_DATA = defineTool({
  name: 'SYNC_DATA',
  handler: async (input, ctx) => {
    await ctx.access.check();
    
    // User needs access to at least ONE of these tools
    // Grants access if user has READ_FROM_SOURCE OR READ_FROM_CACHE
    await ctx.access.check('READ_FROM_SOURCE', 'READ_FROM_CACHE');
    
    // Business logic...
  },
});

// Example 4: Conditional permission checks
export const PROCESS_DOCUMENT = defineTool({
  name: 'PROCESS_DOCUMENT',
  handler: async (input, ctx) => {
    await ctx.access.check();
    
    if (input.useAI) {
      // Only check AI_PROCESS if needed
      await ctx.access.check('AI_PROCESS');
    }
    
    // Business logic...
  },
});

// Example 5: Manual grant for admin override
export const EMERGENCY_ACTION = defineTool({
  name: 'EMERGENCY_ACTION',
  handler: async (input, ctx) => {
    // Custom validation logic
    if (input.emergencyCode === process.env.EMERGENCY_CODE) {
      ctx.access.grant(); // Unconditionally grant access
    } else {
      await ctx.access.check(); // Normal permission check
    }
    
    // Business logic...
  },
});
```

**Step 4: Final Middleware Verifies Grant**

```typescript
// api/middlewares/authorization.ts
app.use('*', async (c, next) => {
  await next();
  
  // After tool execution, verify authorization was handled
  const ctx = c.get('meshContext');
  
  if (!ctx.access.granted()) {
    // Tool forgot to call grant() - if not granted, access is denied
    throw new Error('SECURITY: Tool did not grant access');
  }
});
```

#### 4. Storage Port & Adapter Pattern

Storage ports define the contracts, and adapters implement them for specific databases:

```typescript
// storage/ports.ts
export interface ConnectionStorage {
  create(data: CreateConnectionData): Promise<MCPConnection>;
  findById(id: string): Promise<MCPConnection | null>;
  findByProjectId(projectId: string): Promise<MCPConnection[]>;
  update(id: string, data: Partial<MCPConnection>): Promise<MCPConnection>;
  delete(id: string): Promise<void>;
  
  // Connection-specific queries
  findByTeamId(teamId: string): Promise<MCPConnection[]>;
  testConnection(id: string): Promise<ConnectionTestResult>;
}

// storage/connection.ts
import { Kysely } from 'kysely';
import type { Database, MCPConnection } from './types';

export class ConnectionStorage implements ConnectionStoragePort {
  constructor(private db: Kysely<Database>) {}
  
  async create(data: CreateConnectionData): Promise<MCPConnection> {
    // Kysely query builder works identically across SQLite, PostgreSQL, and MySQL!
    return await this.db
      .insertInto('connections')
      .values({
        id: crypto.randomUUID(),
        projectId: data.projectId,
        name: data.name,
        connectionType: data.connection.type,
        connectionUrl: data.connection.url,
        createdAt: new Date(),
        updatedAt: new Date(),
        // ... other fields
      })
      .returningAll()
      .executeTakeFirstOrThrow();
  }
  
  async findById(id: string): Promise<MCPConnection | null> {
    return await this.db
      .selectFrom('connections')
      .selectAll()
      .where('id', '=', id)
      .executeTakeFirst() ?? null;
  }
  
  async list(projectId: string | null): Promise<MCPConnection[]> {
    // If projectId is null, return organization-scoped connections
    // Otherwise return both organization + project connections
    let query = this.db.selectFrom('connections').selectAll();
    
    if (projectId) {
      // Project-scoped connections for this project
      query = query.where('projectId', '=', projectId);
    } else {
      // Organization-scoped connections only (projectId IS NULL)
      query = query.where('projectId', 'is', null);
    }
    
    return await query.execute();
  }
  
  // ... other methods
}
```

#### 5. Authentication via Better Auth

The Mesh uses [Better Auth's MCP plugin](https://www.better-auth.com/docs/plugins/mcp) for OAuth-based MCP client authentication, along with the [API Key plugin](https://www.better-auth.com/docs/plugins/api-key) for direct tool access:

**Configuration:**

```typescript
// auth/index.ts
import { betterAuth } from "better-auth";
import { apiKey, admin, mcp } from "better-auth/plugins";
import { kyselyAdapter } from "better-auth/adapters/kysely";
import { db } from '../database';

export const auth = betterAuth({
  database: kyselyAdapter(db),
  
  plugins: [
    // MCP plugin for OAuth-based MCP client authentication
    // https://www.better-auth.com/docs/plugins/mcp
    mcp({
      loginPage: "/sign-in", // Path to your login page
      resource: process.env.MCP_RESOURCE_URL || "http://localhost:3000",
    }),
    
    // API Key plugin for direct tool access
    // Reference: https://www.better-auth.com/docs/plugins/api-key
    apiKey({
      permissions: {
        // Default permissions for newly created API keys
        defaultPermissions: {
          'conn_*': ['TOOL_X', 'TOOL_Y'],
        },
      },
    }),
    
    // Admin plugin for role-based access
    admin({
      defaultRole: "user",
      adminRoles: ["admin"],
    }),
  ],
});
```

**API Key Creation:**

Users create API keys with specific permissions using the [Better Auth API Key plugin](https://www.better-auth.com/docs/plugins/api-key):

```typescript
// Server-side API key creation
const result = await auth.api.createApiKey({
  body: {
    name: 'Claude Desktop - Production',
    userId: user.id,
    expiresIn: 60 * 60 * 24 * 90, // 90 days
    prefix: 'mcp',
    
    // Better Auth permission model: { [resource]: [actions...] }
    // https://www.better-auth.com/docs/plugins/api-key#permissions
    permissions: {
      // Organization-level permissions (organization-scoped tools)
      'mcp': ['PROJECT_CREATE', 'PROJECT_LIST', 'PROJECT_GET', 'PROJECT_UPDATE', 'PROJECT_DELETE'],
      
      // Connection-specific permissions (using actual connection UUIDs)
      'conn_123e4567-e89b-12d3-a456-426614174000': ['SEND_MESSAGE', 'LIST_THREADS'], // Slack
      'conn_987fcdeb-51a2-43e1-b234-567890abcdef': ['SEND_EMAIL', 'READ_EMAIL'],      // Gmail
    },
    
    // Built-in rate limiting
    rateLimitEnabled: true,
    rateLimitMax: 1000,
    rateLimitTimeWindow: 60 * 60 * 1000, // 1 hour
    
    // Request limits with auto-refill
    remaining: 10000,
    refillAmount: 1000,
    refillInterval: 24 * 60 * 60 * 1000, // Refill 1000 requests daily
    
    metadata: {
      environment: 'production',
      clientType: 'claude-desktop',
    },
  },
});

// Returns: { id, name, key, start, prefix, userId, permissions, ... }
// Store result.key securely - it won't be retrievable later!
```

**API Key Verification:**

MCP endpoints verify API keys with permission checks:

```typescript
// Verify API key with required permissions
const result = await auth.api.verifyApiKey({
  body: {
    key: 'mcp_abc123...', // From Authorization: Bearer header
    
    // Check specific permissions (optional)
    permissions: {
      'mcp': ['PROJECT_LIST'], // Check organization-level tool access
      'conn_123e4567-e89b-12d3-a456-426614174000': ['SEND_MESSAGE'], // Check specific connection access
    },
  },
});

if (result.valid) {
  // API key is valid and has required permissions
  const { key } = result;
  // key contains: { id, userId, name, permissions, metadata, remaining, ... }
  
  // Use key.permissions to check additional access
  // Use key.userId to load user context
  // Use key.metadata for client-specific behavior
} else {
  // result.error contains { message, code }
  throw new UnauthorizedError(result.error.message);
}
```

**API Key Management:**

```typescript
// List user's API keys
const keys = await auth.api.listApiKeys({
  headers: await headers(),
});

// Update API key permissions
await auth.api.updateApiKey({
  body: {
    keyId: 'key_abc123',
    permissions: {
      'mcp': ['PROJECT_CREATE', 'PROJECT_LIST', 'PROJECT_GET'],
      'conn_123e4567-e89b-12d3-a456-426614174000': ['SEND_MESSAGE', 'LIST_THREADS', 'DELETE_MESSAGE'],
    },
    remaining: 5000, // Update remaining requests
  },
  headers: await headers(),
});

// Revoke API key (instant)
await auth.api.deleteApiKey({
  body: { keyId: 'key_abc123' },
  headers: await headers(),
});

// Clean up expired keys (cron job)
await auth.api.deleteAllExpiredApiKeys();
```

**Better Auth API Key Benefits:**

1. **Built-in Permissions**: Native support for resource-based permissions (`{ [resource]: [actions] }`)
2. **Rate Limiting**: Built-in per-key rate limiting with configurable windows
3. **Auto-Refill**: Automatic request quota refills on intervals
4. **Expiration**: Set TTL with automatic cleanup
5. **Metadata**: Store arbitrary key-value data per key
6. **Instant Revocation**: Delete keys immediately, no caching issues
7. **Request Tracking**: `remaining`, `requestCount`, `lastRequest` tracked automatically
8. **Secure Hashing**: Keys are hashed (bcrypt/argon2) in the database
9. **Prefix Support**: Custom prefixes for key organization (e.g., `mcp_`, `prod_`)
10. **No Token Overhead**: Simpler than JWT, no signature verification needed

**Permission Model Format:**

The permission model uses actual connection UUIDs (not friendly names) to ensure accurate access control:

```typescript
// ✅ CORRECT: Using actual connection UUIDs and organization-level tools
{
  // Organization-level permissions (organization-scoped tools)
  "mcp": ["PROJECT_CREATE", "PROJECT_LIST", "PROJECT_GET", "PROJECT_UPDATE", "PROJECT_DELETE"],
  
  // Connection-specific permissions (UUID from database)
  "conn_123e4567-e89b-12d3-a456-426614174000": ["SEND_MESSAGE", "LIST_THREADS", "DELETE_MESSAGE"],
  "conn_987fcdeb-51a2-43e1-b234-567890abcdef": ["SEND_EMAIL", "READ_EMAIL"],
  "conn_456789ab-cdef-0123-4567-89abcdef0123": ["READ_CALENDAR", "CREATE_EVENT"],
}

// ❌ INCORRECT: Don't use friendly names or generic action verbs
{
  "conn_slack": ["SEND_MESSAGE"],          // Wrong! Use actual UUID
  "conn_gmail": ["SEND_EMAIL"],            // Wrong! Use actual UUID
  "mcp:tools": ["read", "execute"],        // Wrong! Use actual tool names
  "mcp:connections": ["read", "write"],    // Wrong! Use actual tool names
}
```

**Why UUIDs?**

1. **Immutable**: Connection names can change, UUIDs never change
2. **Unique**: Prevents permission conflicts across renamed connections
3. **Secure**: Prevents permission bypasses via name collisions
4. **Consistent**: Matches how connections are stored in the database

**Understanding Permission Resources:**

The Mesh uses a hierarchical permission model with different resource types:

1. **`"mcp"`** - Organization-level resource
   - Contains organization-scoped tools (tools that operate at the cluster level)
   - Example tools: `PROJECT_CREATE`, `PROJECT_LIST`, `PROJECT_GET`, `PROJECT_UPDATE`, `PROJECT_DELETE`
   - These tools don't belong to a specific connection
   - Example: `{ "mcp": ["PROJECT_CREATE", "PROJECT_LIST"] }`

2. **`"conn_<UUID>"`** - Connection-specific resource
   - Contains tools exposed by a specific MCP connection
   - Example tools: `SEND_MESSAGE`, `LIST_THREADS`, `SEND_EMAIL`, `READ_CALENDAR`
   - Each connection has its own set of available tools
   - Example: `{ "conn_123e4567-e89b-12d3-a456-426614174000": ["SEND_MESSAGE"] }`

3. **`"project:<projectId>"`** - Project-specific resource (optional)
   - For custom project-level permissions
   - Example: `{ "project:proj_abc123": ["custom_action"] }`

**When to use each resource:**

- Use `"mcp"` when granting permissions to **manage projects** (organization-level operations)
- Use `"conn_<UUID>"` when granting permissions to **use specific MCP connections** (connection-level operations)
- Use `"project:<projectId>"` for **custom project-specific permissions** (if needed)

#### 5.1 Setting Up Roles and Permissions

The Mesh uses [Better Auth's Admin plugin](https://www.better-auth.com/docs/plugins/admin) for role-based access control. You can define roles with specific permissions:

```typescript
// Example: Creating roles with permissions
await auth.api.createUser({
  body: {
    email: "[email protected]",
    password: "secure-password",
    name: "Admin User",
    role: "admin", // Built-in admin role
  }
});

// Example: Creating a user with custom role
await auth.api.createUser({
  body: {
    email: "[email protected]",
    password: "secure-password",
    name: "Developer User",
    role: "developer",
  }
});

// Example: Setting user role
await auth.api.setRole({
  body: {
    userId: "user_abc123",
    role: "developer",
  }
});

// Example: Checking permissions
const result = await auth.api.userHasPermission({
  body: {
    userId: "user_abc123",
    role: "developer",
    permission: {
      "conn_123e4567-e89b-12d3-a456-426614174000": ["SEND_MESSAGE"]
    }
  }
});

if (result.data?.has) {
  // User has permission
}
```

**Default Roles:**

- **`admin`**: Full access to all resources (bypasses permission checks)
- **`user`**: Default role for new users (requires explicit permissions)
- **Custom roles**: Define your own roles with specific permissions

**Permission Inheritance:**

- Admin role bypasses all permission checks
- Custom roles require explicit permissions per connection/resource
- API keys have their own independent permissions

#### 5.2 MCP OAuth Authentication

The [Better Auth MCP plugin](https://www.better-auth.com/docs/plugins/mcp) automatically handles OAuth 2.1 for MCP clients, providing standard OAuth discovery endpoints and token management.

**OAuth Discovery Metadata Routes:**

Better Auth's MCP plugin automatically handles these endpoints. In your Hono app, the routes are automatically mounted when you use Better Auth's handler:

```typescript
// api/index.ts (Main Hono app)
import { Hono } from 'hono';
import { auth } from '../auth';

const app = new Hono();

// Mount Better Auth handler - automatically includes MCP OAuth endpoints:
// - /.well-known/oauth-authorization-server
// - /.well-known/oauth-protected-resource
// - /oauth/authorize
// - /oauth/token
// - /oauth/register (Dynamic Client Registration)
app.on(['GET', 'POST'], '/api/auth/*', (c) => auth.handler(c.req.raw));

// Your custom routes
app.get('/mcp/tools/:toolName', async (c) => {
  // ... tool execution
});

export default app;
```

**MCP Session Handling with Hono:**

Use Better Auth's `auth.api.getMcpSession` to handle MCP client authentication in your Hono routes:

```typescript
// api/routes/mcp.ts
import { Hono } from 'hono';
import { HTTPException } from 'hono/http-exception';
import { auth } from '../../auth';

const app = new Hono();

// MCP proxy endpoint with OAuth authentication
app.post('/mcp/:connectionId', async (c) => {
  // Get MCP session from OAuth access token
  const session = await auth.api.getMcpSession({
    headers: c.req.raw.headers
  });
  
  if (!session) {
    // Return 401 with WWW-Authenticate header (RFC 9728)
    throw new HTTPException(401, {
      res: new Response(null, {
        status: 401,
        headers: {
          'WWW-Authenticate': `Bearer realm="${c.req.url}", error="invalid_token"`,
        },
      }),
    });
  }
  
  // session contains:
  // - session.user: User who authorized the MCP client
  // - session.scopes: OAuth scopes granted (e.g., "mcp")
  // - session.accessToken: Access token details
  
  const connectionId = c.req.param('connectionId');
  const ctx = c.get('meshContext');
  
  // Check authorization for this specific connection
  await ctx.access.check(connectionId);
  
  // Proxy MCP request to downstream connection
  return proxyToConnection(connectionId, c.req.raw, ctx);
});

export default app;
```

**Alternative: Using Hono Middleware for MCP Auth:**

You can also create a reusable middleware for MCP authentication:

```typescript
// middleware/mcp-auth.ts
import { createMiddleware } from 'hono/factory';
import { HTTPException } from 'hono/http-exception';
import { auth } from '../../auth';

export const requireMcpAuth = () => {
  return createMiddleware(async (c, next) => {
    const session = await auth.api.getMcpSession({
      headers: c.req.raw.headers
    });
    
    if (!session) {
      throw new HTTPException(401, {
        res: new Response(null, {
          status: 401,
          headers: {
            'WWW-Authenticate': `Bearer realm="${c.req.url}", error="invalid_token"`,
          },
        }),
      });
    }
    
    // Store session in context
    c.set('mcpSession', session);
    await next();
  });
};
```

**Using the middleware:**

```typescript
// api/routes/mcp.ts
import { Hono } from 'hono';
import { requireMcpAuth } from '../middleware/mcp-auth';

const app = new Hono();

app.use('/mcp/*', requireMcpAuth());

app.post('/mcp/:connectionId', async (c) => {
  const session = c.get('mcpSession');
  const connectionId = c.req.param('connectionId');
  const ctx = c.get('meshContext');
  
  await ctx.access.check(connectionId);
  
  return proxyToConnection(connectionId, c.req.raw, ctx);
});

export default app;
```

**Legacy Option (Direct Request Handling):**

If you need to work with raw Request objects:

```typescript
// api/routes/mcp.ts (raw handler style)
import { Hono } from 'hono';
import { auth } from '../../auth';

const app = new Hono();

app.post('/mcp/:connectionId', async (c) => {
  const req = c.req.raw;
  
  // Get MCP session from OAuth access token
  const session = await auth.api.getMcpSession({
    headers: req.headers
  });
  
  if (!session) {
    return new Response(null, {
      status: 401,
      headers: {
        'WWW-Authenticate': 'Bearer realm="MCP Mesh"'
      }
    });
  }
  
  const connectionId = c.req.param('connectionId');
  const ctx = c.get('meshContext');
  
  // Check authorization
  await ctx.access.check(connectionId);
  
  // Proxy MCP request
  return proxyToConnection(connectionId, req, ctx);
});

export default app;
```

**Benefits of Better Auth MCP Plugin:**

1. ✅ **Standard OAuth 2.1**: Full compliance with MCP Authorization Specification
2. ✅ **Automatic Discovery**: OAuth metadata endpoints handled automatically
3. ✅ **PKCE Support**: Built-in support for Proof Key for Code Exchange
4. ✅ **Scope Management**: Manage permissions via OAuth scopes
5. ✅ **Token Management**: Access tokens, refresh tokens, and expiration handled
6. ✅ **User Context**: Access user information in MCP tools
7. ✅ **Session Tracking**: Track which user authorized which MCP client

#### 6. Observability with OpenTelemetry

The Mesh includes comprehensive observability using [OpenTelemetry](https://opentelemetry.io/) for distributed tracing and metrics:

**Configuration:**

```typescript
// observability/index.ts
import { trace, metrics } from '@opentelemetry/api';
import { NodeSDK } from '@opentelemetry/sdk-node';
import { getNodeAutoInstrumentations } from '@opentelemetry/auto-instrumentations-node';
import { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-http';
import { OTLPMetricExporter } from '@opentelemetry/exporter-metrics-otlp-http';
import { PeriodicExportingMetricReader } from '@opentelemetry/sdk-metrics';

const sdk = new NodeSDK({
  traceExporter: new OTLPTraceExporter({
    url: process.env.OTEL_EXPORTER_OTLP_ENDPOINT || 'http://localhost:4318/v1/traces',
  }),
  metricReader: new PeriodicExportingMetricReader({
    exporter: new OTLPMetricExporter({
      url: process.env.OTEL_EXPORTER_OTLP_ENDPOINT || 'http://localhost:4318/v1/metrics',
    }),
    exportIntervalMillis: 10000, // Export every 10 seconds
  }),
  instrumentations: [getNodeAutoInstrumentations()],
  serviceName: 'mcp-mesh',
});

sdk.start();

// Export tracer and meter for use in tools
export const tracer = trace.getTracer('mcp-mesh', '1.0.0');
export const meter = metrics.getMeter('mcp-mesh', '1.0.0');

// Create metrics
export const metrics = {
  toolExecutionDuration: meter.createHistogram('tool.execution.duration', {
    description: 'Duration of tool executions in milliseconds',
    unit: 'ms',
  }),
  toolExecutionCount: meter.createCounter('tool.execution.count', {
    description: 'Number of tool executions',
  }),
  toolExecutionErrors: meter.createCounter('tool.execution.errors', {
    description: 'Number of tool execution errors',
  }),
  connectionProxyRequests: meter.createCounter('connection.proxy.requests', {
    description: 'Number of MCP proxy requests',
  }),
  connectionProxyErrors: meter.createCounter('connection.proxy.errors', {
    description: 'Number of MCP proxy errors',
  }),
  activeConnections: meter.createUpDownCounter('connections.active', {
    description: 'Number of active MCP connections',
  }),
};
```

**Usage in Tools:**

```typescript
// defineTool automatically adds tracing and metrics
export const CONNECTION_CREATE = defineTool({
  name: 'CONNECTION_CREATE',
  // ... schema ...
  handler: async (input, ctx) => {
    // Start a span for this operation
    return await ctx.tracer.startActiveSpan('connection.create', async (span) => {
      try {
        // Add attributes to span
        span.setAttribute('connection.name', input.name);
        span.setAttribute('connection.type', input.connection.type);
        span.setAttribute('project.id', ctx.project?.id ?? 'organization');
        
        // Check authorization
        await ctx.access.check();
        
        // Create connection
        const connection = await ctx.storage.connections.create({
          projectId: ctx.project?.id ?? null,
          ...input,
          createdById: ctx.auth.user!.id,
        });
        
        // Record success metric
        ctx.meter.createCounter('connections.created').add(1, {
          scope: connection.projectId ? 'project' : 'organization',
        });
        
        span.setStatus({ code: SpanStatusCode.OK });
        return connection;
      } catch (error) {
        // Record error
        span.setStatus({ 
          code: SpanStatusCode.ERROR,
          message: error.message,
        });
        span.recordException(error);
        throw error;
      } finally {
        span.end();
      }
    });
  },
});
```

**Automatic Metrics in `defineTool`:**

The `defineTool` wrapper automatically collects metrics for all tool executions:

```typescript
// core/define-tool.ts (enhanced with observability)
export function defineTool<TInput extends z.ZodType, TOutput extends z.ZodType>(
  definition: ToolDefinition<TInput, TOutput>
) {
  return {
    ...definition,
    execute: async (input: z.infer<TInput>, ctx: MeshContext): Promise<z.infer<TOutput>> => {
      const startTime = Date.now();
      
      return await ctx.tracer.startActiveSpan(
        `tool.${definition.name}`,
        { attributes: { 'tool.name': definition.name } },
        async (span) => {
          try {
            ctx.toolName = definition.name;
            
            // MCP already validated input/output against JSON Schema
            // Execute handler directly
            const output = await definition.handler(input, ctx);
            
            // Record metrics
            const duration = Date.now() - startTime;
            ctx.meter.createHistogram('tool.execution.duration').record(duration, {
              'tool.name': definition.name,
              'project.id': ctx.project?.id ?? 'organization',
              'user.id': ctx.auth.user?.id ?? 'anonymous',
            });
            
            ctx.meter.createCounter('tool.execution.count').add(1, {
              'tool.name': definition.name,
              'status': 'success',
            });
            
            // Audit log
            await ctx.storage.auditLogs.log({
              projectId: ctx.project?.id,
              userId: ctx.auth.user?.id,
              toolName: definition.name,
              allowed: ctx.access.granted(),
              duration,
              timestamp: new Date(),
              requestMetadata: { input },
            });
            
            span.setStatus({ code: SpanStatusCode.OK });
            return output;
          } catch (error) {
            // Record error metrics
            ctx.meter.createCounter('tool.execution.errors').add(1, {
              'tool.name': definition.name,
              'error.type': error.constructor.name,
            });
            
            span.setStatus({ 
              code: SpanStatusCode.ERROR,
              message: error.message,
            });
            span.recordException(error);
            throw error;
          } finally {
            span.end();
          }
        }
      );
    },
  };
}
```

**Standard Metrics:**

The Mesh automatically tracks:

1. **Tool Execution Metrics:**
   - `tool.execution.duration` - Histogram of execution times
   - `tool.execution.count` - Counter of executions (by tool, status)
   - `tool.execution.errors` - Counter of errors (by tool, error type)

2. **Connection Metrics:**
   - `connections.active` - Active connections gauge
   - `connections.created` - Total connections created
   - `connection.proxy.requests` - MCP proxy requests
   - `connection.proxy.errors` - MCP proxy errors
   - `connection.proxy.duration` - Proxy request duration

3. **Authorization Metrics:**
   - `auth.checks.total` - Total authorization checks
   - `auth.checks.denied` - Authorization denials
   - `auth.checks.duration` - Authorization check duration

**Tracing Context Propagation:**

When proxying MCP calls, the Mesh propagates trace context:

```typescript
// Proxy with trace propagation
const headers = {
  ...connection.headers,
  // Propagate W3C Trace Context
  'traceparent': ctx.tracer.getActiveSpan()?.spanContext().traceId,
};

const response = await fetch(connection.url, { headers });
```

#### 7. Downstream MCP OAuth Client

The Mesh acts as an **OAuth client** to connect to downstream MCPs that require OAuth authentication. This allows the Mesh to proxy requests to third-party OAuth-protected MCPs while keeping credentials secure.

**Three OAuth Roles:**

```typescript
// 1. AUTHORIZATION SERVER (for MCP clients connecting to the Mesh)
//    ✅ Handled by Better Auth MCP plugin automatically
//    - Issues access tokens to MCP clients (Claude Desktop, etc.)
//    - Handles user authorization flows
//    - Implements Dynamic Client Registration (RFC7591)

// 2. RESOURCE SERVER (for the Mesh's own tools)
//    ✅ Handled by Better Auth automatically
//    - Validates tokens using Better Auth MCP plugin
//    - Protects MCP tools with OAuth scopes/permissions

// 3. OAUTH CLIENT (for downstream MCPs)
//    ⚙️  We need to implement this
//    - Obtains tokens from downstream MCPs' auth servers
//    - Proxies requests with proper token audience binding (RFC 8707)
//    - Caches and refreshes tokens automatically
```

**Note**: The first two roles (Authorization Server and Resource Server) are handled automatically by [Better Auth's MCP plugin](https://www.better-auth.com/docs/plugins/mcp). We only need to implement the OAuth client functionality for connecting to downstream OAuth-protected MCPs.

**Connecting to Downstream OAuth-Protected MCPs:**

When creating a connection to a downstream MCP that supports OAuth, the Mesh can act as an OAuth client to obtain tokens. See the "Discovering and Connecting to Downstream OAuth MCPs" section below for implementation details.

**Database Schema for OAuth (Kysely TypeScript Interfaces):**

With Kysely, you define database schema as TypeScript interfaces, not dialect-specific table builders. This makes your schema truly database-agnostic:

```typescript
// storage/types.ts
import { Hono } from 'hono';
import { HTTPException } from 'hono/http-exception';

export function requireMcpAuth(requiredScopes: string[] = []) {
  return async (c: Context, next: Next) => {
    const authorization = c.req.header('Authorization');
    
    if (!authorization?.startsWith('Bearer ')) {
      // Return 401 with WWW-Authenticate header (RFC9728)
      throw new HTTPException(401, {
        res: new Response('Unauthorized', {
          status: 401,
          headers: {
            'WWW-Authenticate': [
              `Bearer realm="MCP Mesh"`,
              `resource_metadata="${c.env.BASE_URL}/.well-known/oauth-protected-resource"`,
              `scope="${requiredScopes.join(' ')}"`,
            ].join(', '),
          },
        }),
      });
    }
    
    const token = authorization.slice(7);
    
    try {
      // Verify token with Better Auth JWT
      const payload = await c.get('auth').api.verifySession({ 
        token,
      });
      
      // Check scopes
      if (requiredScopes.length > 0) {
        const tokenScopes = payload.scopes ?? [];
        const hasRequiredScopes = requiredScopes.every(s => tokenScopes.includes(s));
        
        if (!hasRequiredScopes) {
          throw new HTTPException(403, {
            res: new Response('Forbidden', {
              status: 403,
              headers: {
                'WWW-Authenticate': [
                  `Bearer error="insufficient_scope"`,
                  `scope="${requiredScopes.join(' ')}"`,
                  `resource_metadata="${c.env.BASE_URL}/.well-known/oauth-protected-resource"`,
                  `error_description="Missing required scopes"`,
                ].join(', '),
              },
            }),
          });
        }
      }
      
      c.set('user', payload);
      await next();
    } catch (error) {
      throw new HTTPException(401, {
        res: new Response('Invalid token', {
          status: 401,
          headers: {
            'WWW-Authenticate': `Bearer error="invalid_token", error_description="${error.message}"`,
          },
        }),
      });
    }
  };
}
```

**MCP Proxy with OAuth:**

When proxying to downstream MCPs, the Mesh obtains and uses proper tokens:

```typescript
// Proxy MCP request with OAuth token
app.post('/mcp/:connectionId', requireMcpAuth(), async (c) => {
  const { connectionId } = c.req.param();
  const ctx = c.get('meshContext');
  
  // Start trace span
  return await ctx.tracer.startActiveSpan('mcp.proxy', async (span) => {
    // Get connection details (with stored OAuth config if available)
    const connection = await ctx.storage.connections.findById(connectionId);
    
    if (!connection) {
      throw new HTTPException(404, { message: 'Connection not found' });
    }
    
    // Check authorization (connection-specific)
    await ctx.access.check(connectionId);
    
    span.setAttribute('connection.id', connectionId);
    span.setAttribute('connection.name', connection.name);
    span.setAttribute('connection.has_oauth', !!connection.oauthConfig);
    
    // Get or create OAuth token for downstream MCP
    // Note: OAuth config was already discovered when connection was created
    let downstreamToken: string;
    
    if (connection.oauthConfig) {
      // Downstream MCP has OAuth - get cached token or obtain new one
      // Uses stored OAuth config (clientId, clientSecret, endpoints, etc.)
      downstreamToken = await getDownstreamToken({
        connection,
        user: ctx.auth.user!,
        resource: connection.url, // RFC 8707 Resource Indicator
      });
    } else {
      // Downstream MCP has no OAuth - use static token from connection config
      downstreamToken = connection.token ?? await ctx.jwt.issue({
        sub: ctx.auth.user!.id,
        aud: connection.url,
        projectId: ctx.project?.id,
      });
    }
    
    // Proxy request with W3C Trace Context propagation
    const response = await fetch(connection.url, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${downstreamToken}`,
        'traceparent': span.spanContext().traceId, // OpenTelemetry trace propagation
      },
      body: JSON.stringify(await c.req.json()),
    });
    
    // Record metrics
    ctx.meter.createCounter('connection.proxy.requests').add(1, {
      'connection.id': connectionId,
      'status': response.status.toString(),
    });
    
    if (!response.ok) {
      ctx.meter.createCounter('connection.proxy.errors').add(1, {
        'connection.id': connectionId,
      });
      
      span.setStatus({ code: SpanStatusCode.ERROR });
    }
    
    span.end();
    return response;
  });
});
```

**Database Schema for OAuth Clients:**

```typescript
// storage/types.ts
import { Generated, ColumnType } from 'kysely';

// With Kysely, you define database schema as TypeScript interfaces
// The dialect is specified once when creating the Kysely instance
// No need for sqliteTable, pgTable, or mysqlTable!

// OAuth Clients table
export interface OAuthClient {
  id: string;
  clientId: string; // Unique
  clientSecret: string | null; // Hashed, null for public clients
  clientName: string;
  redirectUris: string[]; // JSON array
  grantTypes: string[]; // JSON array
  scope: string | null;
  clientUri: string | null;
  logoUri: string | null;
  createdAt: ColumnType<Date, Date | string, never>;
}

// OAuth Authorization Codes table
export interface OAuthAuthorizationCode {
  code: string; // Primary key
  clientId: string; // Foreign key
  userId: string;
  redirectUri: string;
  scope: string | null;
  codeChallenge: string | null; // PKCE
  codeChallengeMethod: string | null; // 'S256'
  expiresAt: ColumnType<Date, Date | string, never>;
  createdAt: ColumnType<Date, Date | string, never>;
}

// OAuth Refresh Tokens table
export interface OAuthRefreshToken {
  token: string; // Primary key
  clientId: string; // Foreign key
  userId: string;
  scope: string | null;
  expiresAt: ColumnType<Date, Date | string, never> | null;
  createdAt: ColumnType<Date, Date | string, never>;
}

// Downstream Tokens table (cache tokens from downstream MCPs)
export interface DownstreamToken {
  id: string; // Primary key
  connectionId: string; // Foreign key
  userId: string | null; // Null for client_credentials tokens
  accessToken: string; // Encrypted
  refreshToken: string | null; // Encrypted
  scope: string | null;
  expiresAt: ColumnType<Date, Date | string, never> | null;
  createdAt: ColumnType<Date, Date | string, never>;
  updatedAt: ColumnType<Date, Date | string, Date | string>;
}

// Database schema interface (used by Kysely<Database>)
export interface Database {
  connections: MCPConnection;
  projects: Project;
  roles: Role;
  users: User;
  apiKeys: ApiKey;
  auditLogs: AuditLog;
  
  // OAuth tables
  oauth_clients: OAuthClient;
  oauth_authorization_codes: OAuthAuthorizationCode;
  oauth_refresh_tokens: OAuthRefreshToken;
  downstream_tokens: DownstreamToken;
}
```

**Benefits of Kysely's Type-Only Schema:**

1. ✅ **True Database Agnostic**: No switching between `sqliteTable`, `pgTable`, `mysqlTable`
2. ✅ **Single Dialect Specification**: Set dialect once in `createDatabase()`, not in every schema file
3. ✅ **Type-Safe Queries**: Full TypeScript inference throughout
4. ✅ **Simple**: Just TypeScript interfaces, no complex builders
5. ✅ **Portable**: Same schema works for SQLite, PostgreSQL, and MySQL
6. ✅ **Better Auth Compatible**: [kyselyAdapter](https://www.better-auth.com/docs/adapters/kysely) handles schema automatically

**Discovering and Connecting to Downstream OAuth MCPs:**

**Important**: OAuth discovery and client registration only happen **once** when creating or configuring a connection. The proxy itself doesn't perform OAuth discovery on every request - it uses the stored OAuth configuration from the connection.

When creating a connection to a downstream MCP that supports OAuth, the Mesh follows the [MCP Authorization Discovery flow](https://modelcontextprotocol.io/specification/draft/basic/authorization):

```typescript
// tools/connection/discover-oauth.ts
export async function discoverDownstreamOAuth(url: string): Promise<OAuthConfig | null> {
  try {
    // Step 1: Try to get Protected Resource Metadata
    let resourceMetadata: any;
    
    // Try well-known URI first
    const wellKnownUrl = new URL('/.well-known/oauth-protected-resource', url);
    const response = await fetch(wellKnownUrl.toString());
    
    if (!response.ok) {
      // Try making a request to get WWW-Authenticate header
      const testResponse = await fetch(url, { 
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ jsonrpc: '2.0', method: 'initialize', id: 1 }),
      });
      
      if (testResponse.status === 401) {
        const wwwAuth = testResponse.headers.get('WWW-Authenticate');
        const metadataUrl = parseResourceMetadataUrl(wwwAuth);
        
        if (metadataUrl) {
          const metadataResponse = await fetch(metadataUrl);
          resourceMetadata = await metadataResponse.json();
        }
      }
    } else {
      resourceMetadata = await response.json();
    }
    
    if (!resourceMetadata?.authorization_servers?.[0]) {
      return null; // No OAuth support
    }
    
    // Step 2: Discover Authorization Server Metadata
    const authServerUrl = resourceMetadata.authorization_servers[0];
    const authMetadata = await discoverAuthServer(authServerUrl);
    
    if (!authMetadata) {
      throw new Error('Failed to discover authorization server metadata');
    }
    
    // Step 3: Attempt Dynamic Client Registration
    if (authMetadata.registration_endpoint) {
      const registration = await fetch(authMetadata.registration_endpoint, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          client_name: 'MCP Mesh',
          redirect_uris: [`https://mesh.example.com/oauth/callback`], // Use configured base URL
          grant_types: ['authorization_code', 'refresh_token', 'client_credentials'],
          token_endpoint_auth_method: 'client_secret_basic',
          scope: resourceMetadata.scopes_supported?.join(' '),
        }),
      });
      
      if (registration.ok) {
        const client = await registration.json();
        
        return {
          authorizationEndpoint: authMetadata.authorization_endpoint,
          tokenEndpoint: authMetadata.token_endpoint,
          introspectionEndpoint: authMetadata.introspection_endpoint,
          clientId: client.client_id,
          clientSecret: client.client_secret,
          scopes: resourceMetadata.scopes_supported || [],
          grantType: 'authorization_code',
        };
      }
    }
    
    // Step 4: Fallback - return metadata for manual configuration
    return {
      authorizationEndpoint: authMetadata.authorization_endpoint,
      tokenEndpoint: authMetadata.token_endpoint,
      introspectionEndpoint: authMetadata.introspection_endpoint,
      clientId: '', // User must configure manually
      clientSecret: undefined,
      scopes: resourceMetadata.scopes_supported || [],
      grantType: 'authorization_code',
    };
  } catch (error) {
    console.error('OAuth discovery failed:', error);
    return null;
  }
}

async function discoverAuthServer(issuerUrl: string): Promise<any> {
  const issuer = new URL(issuerUrl);
  const hasPath = issuer.pathname !== '/';
  
  const endpoints = hasPath
    ? [
        `${issuer.origin}/.well-known/oauth-authorization-server${issuer.pathname}`,
        `${issuer.origin}/.well-known/openid-configuration${issuer.pathname}`,
        `${issuerUrl}/.well-known/openid-configuration`,
      ]
    : [
        `${issuerUrl}/.well-known/oauth-authorization-server`,
        `${issuerUrl}/.well-known/openid-configuration`,
      ];
  
  for (const endpoint of endpoints) {
    try {
      const response = await fetch(endpoint);
      if (response.ok) {
        return await response.json();
      }
    } catch {
      continue;
    }
  }
  
  return null;
}
```

**Obtaining Tokens for Downstream MCPs:**

```typescript
// auth/downstream-token-manager.ts

interface DownstreamTokenCache {
  connectionId: string;
  userId?: string; // For authorization_code flow
  accessToken: string;
  refreshToken?: string;
  expiresAt: Date;
}

export async function getDownstreamToken(opts: {
  connection: MCPConnection;
  user: User;
  resource: string;
}): Promise<string> {
  const { connection, user, resource } = opts;
  
  if (!connection.oauthConfig) {
    throw new Error('Connection does not have OAuth configured');
  }
  
  // Check token cache
  const cached = await findCachedToken(connection.id, user.id);
  
  if (cached && cached.expiresAt > new Date(Date.now() + 60000)) {
    return cached.accessToken; // Valid for at least 1 more minute
  }
  
  // Token expired or missing - obtain new token
  if (connection.oauthConfig.grantType === 'client_credentials') {
    // Service-to-service token (no user context)
    return await obtainClientCredentialsToken(connection, resource);
  } else {
    // User-specific token (requires user authorization)
    if (cached?.refreshToken) {
      // Try refresh first
      try {
        return await refreshToken(connection, cached.refreshToken, resource);
      } catch {
        // Refresh failed, need new authorization
      }
    }
    
    // Need user authorization
    throw new Error('USER_AUTHORIZATION_REQUIRED', {
      authorizationUrl: buildAuthorizationUrl(connection, user, resource),
    });
  }
}

async function obtainClientCredentialsToken(
  connection: MCPConnection,
  resource: string
): Promise<string> {
  const { oauthConfig } = connection;
  
  const params = new URLSearchParams({
    grant_type: 'client_credentials',
    client_id: oauthConfig.clientId,
    scope: oauthConfig.scopes.join(' '),
    resource, // RFC 8707 - Token audience binding
  });
  
  if (oauthConfig.clientSecret) {
    params.set('client_secret', await decryptSecret(oauthConfig.clientSecret));
  }
  
  const response = await fetch(oauthConfig.tokenEndpoint, {
    method: 'POST',
    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
    body: params.toString(),
  });
  
  if (!response.ok) {
    throw new Error(`Token request failed: ${response.status}`);
  }
  
  const data = await response.json();
  
  // Cache the token
  await cacheToken({
    connectionId: connection.id,
    accessToken: data.access_token,
    expiresAt: new Date(Date.now() + (data.expires_in * 1000)),
  });
  
  return data.access_token;
}

function buildAuthorizationUrl(
  connection: MCPConnection,
  user: User,
  resource: string,
  baseUrl: string // Derived from context
): string {
  const { oauthConfig } = connection;
  
  const state = crypto.randomUUID();
  const codeVerifier = generatePKCEVerifier();
  const codeChallenge = generatePKCEChallenge(codeVerifier);
  
  // Store PKCE verifier and state for callback
  storePendingAuthorization({
    state,
    codeVerifier,
    connectionId: connection.id,
    userId: user.id,
    resource,
  });
  
  const params = new URLSearchParams({
    response_type: 'code',
    client_id: oauthConfig.clientId,
    redirect_uri: `${baseUrl}/oauth/callback`,
    scope: oauthConfig.scopes.join(' '),
    state,
    code_challenge: codeChallenge,
    code_challenge_method: 'S256',
    resource, // RFC 8707
  });
  
  return `${oauthConfig.authorizationEndpoint}?${params.toString()}`;
}
```

**OAuth Callback Handler:**

```typescript
// auth/oauth-callback.ts
export const oauthCallbackRouter = new Hono();

oauthCallbackRouter.get('/oauth/callback', async (c) => {
  const code = c.req.query('code');
  const state = c.req.query('state');
  const error = c.req.query('error');
  
  if (error) {
    return c.json({ error, error_description: c.req.query('error_description') }, 400);
  }
  
  if (!code || !state) {
    return c.json({ error: 'Missing code or state parameter' }, 400);
  }
  
  // Retrieve pending authorization
  const pending = await retrievePendingAuthorization(state);
  
  if (!pending) {
    return c.json({ error: 'Invalid or expired state' }, 400);
  }
  
  // Get connection details using Kysely
  const ctx = c.get('meshContext') as MeshContext;
  const connection = await ctx.db
    .selectFrom('connections')
    .selectAll()
    .where('id', '=', pending.connectionId)
    .executeTakeFirst();
  
  if (!connection?.oauthConfig) {
    return c.json({ error: 'Connection not found or not configured for OAuth' }, 404);
  }
  
  const { oauthConfig } = connection;
  
  // Exchange code for tokens
  const params = new URLSearchParams({
    grant_type: 'authorization_code',
    code,
    redirect_uri: `${ctx.baseUrl}/oauth/callback`,
    client_id: oauthConfig.clientId,
    code_verifier: pending.codeVerifier, // PKCE
    resource: pending.resource, // RFC 8707
  });
  
  if (oauthConfig.clientSecret) {
    params.set('client_secret', await decryptSecret(oauthConfig.clientSecret));
  }
  
  const response = await fetch(oauthConfig.tokenEndpoint, {
    method: 'POST',
    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
    body: params.toString(),
  });
  
  if (!response.ok) {
    return c.json({ error: 'Token exchange failed' }, 500);
  }
  
  const tokens = await response.json();
  
  // Cache tokens
  await cacheToken({
    connectionId: pending.connectionId,
    userId: pending.userId,
    accessToken: tokens.access_token,
    refreshToken: tokens.refresh_token,
    expiresAt: new Date(Date.now() + (tokens.expires_in * 1000)),
  });
  
  // Clean up pending authorization
  await deletePendingAuthorization(state);
  
  return c.html(`
    <html>
      <body>
        <h1>Authorization Successful</h1>
        <p>You can close this window and return to your application.</p>
        <script>window.close();</script>
      </body>
    </html>
  `);
});
```

**Complete Example: MCP Client Using the Mesh:**

```typescript
// Example: Claude Desktop or any MCP client connecting to the Mesh

import { Client } from '@modelcontextprotocol/sdk/client/index.js';
import { StreamableHTTPClientTransport } from '@modelcontextprotocol/sdk/client/streamableHttp.js';
import { createRemoteJWKSet, jwtVerify } from 'jose';

const MESH_URL = 'https://mesh.example.com/mcp';

async function connectToMesh() {
  // Step 1: Discover OAuth metadata
  const resourceMetadata = await fetch(`${MESH_URL}/.well-known/oauth-protected-resource`)
    .then(r => r.json());
  
  const authServerUrl = resourceMetadata.authorization_servers[0];
  const authMetadata = await fetch(`${authServerUrl}/.well-known/oauth-authorization-server`)
    .then(r => r.json());
  
  // Step 2: Dynamic Client Registration
  const client = await fetch(authMetadata.registration_endpoint, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      client_name: 'Claude Desktop',
      redirect_uris: ['http://localhost:3000/oauth/callback'],
      grant_types: ['authorization_code', 'refresh_token'],
      token_endpoint_auth_method: 'none', // Public client with PKCE
      scope: 'mcp:tools mcp:connections:read',
    }),
  }).then(r => r.json());
  
  console.log('Registered client:', client.client_id);
  
  // Step 3: Authorization Code Flow with PKCE
  const codeVerifier = generatePKCEVerifier();
  const codeChallenge = await generatePKCEChallenge(codeVerifier);
  const state = crypto.randomUUID();
  
  const authUrl = new URL(authMetadata.authorization_endpoint);
  authUrl.searchParams.set('response_type', 'code');
  authUrl.searchParams.set('client_id', client.client_id);
  authUrl.searchParams.set('redirect_uri', 'http://localhost:3000/oauth/callback');
  authUrl.searchParams.set('scope', 'mcp');
  authUrl.searchParams.set('state', state);
  authUrl.searchParams.set('code_challenge', codeChallenge);
  authUrl.searchParams.set('code_challenge_method', 'S256');
  authUrl.searchParams.set('resource', MESH_URL); // RFC 8707 - Audience binding
  
  console.log('Open this URL to authorize:', authUrl.toString());
  
  // ... After user authorizes and is redirected back with code ...
  const code = '...'; // From callback
  
  // Step 4: Exchange code for tokens
  const tokenResponse = await fetch(authMetadata.token_endpoint, {
    method: 'POST',
    headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
    body: new URLSearchParams({
      grant_type: 'authorization_code',
      code,
      redirect_uri: 'http://localhost:3000/oauth/callback',
      client_id: client.client_id,
      code_verifier: codeVerifier,
      resource: MESH_URL, // RFC 8707
    }).toString(),
  }).then(r => r.json());
  
  const { access_token, refresh_token } = tokenResponse;
  
  // Step 5: Verify token (optional, for demonstration)
  const JWKS = createRemoteJWKSet(new URL(`${authServerUrl}/.well-known/jwks`));
  const { payload } = await jwtVerify(access_token, JWKS, {
    issuer: authServerUrl,
    audience: MESH_URL,
  });
  
  console.log('Token verified! Payload:', payload);
  
  // Step 6: Connect to MCP with Bearer token
  const transport = new StreamableHTTPClientTransport({
    url: MESH_URL,
    headers: {
      'Authorization': `Bearer ${access_token}`,
    },
  });
  
  const mcpClient = new Client({
    name: 'claude-desktop',
    version: '1.0.0',
  }, {
    capabilities: {},
  });
  
  await mcpClient.connect(transport);
  
  // Step 7: List available tools
  const tools = await mcpClient.listTools();
  console.log('Available tools:', tools.tools.map(t => t.name));
  
  // Step 8: Call a tool
  const result = await mcpClient.callTool({
    name: 'CONNECTION_CREATE',
    arguments: {
      name: 'My Gmail',
      connection: {
        type: 'HTTP',
        url: 'https://mcp.gmail.com',
      },
    },
  });
  
  console.log('Tool result:', result);
}

// PKCE helpers
function generatePKCEVerifier(): string {
  const array = new Uint8Array(32);
  crypto.getRandomValues(array);
  return base64URLEncode(array);
}

async function generatePKCEChallenge(verifier: string): Promise<string> {
  const encoder = new TextEncoder();
  const data = encoder.encode(verifier);
  const digest = await crypto.subtle.digest('SHA-256', data);
  return base64URLEncode(new Uint8Array(digest));
}

function base64URLEncode(buffer: Uint8Array): string {
  return btoa(String.fromCharCode(...buffer))
    .replace(/\+/g, '-')
    .replace(/\//g, '_')
    .replace(/=/g, '');
}
```

**Handling Unauthorized Responses:**

```typescript
// When a tool call returns 401 or 403, handle the challenge
async function callToolWithRetry(client: Client, toolName: string, args: any) {
  try {
    return await client.callTool({ name: toolName, arguments: args });
  } catch (error) {
    if (error.status === 401) {
      // Token expired - use refresh token
      const newToken = await refreshAccessToken();
      // Update transport with new token
      // Retry the call
      return await client.callTool({ name: toolName, arguments: args });
    }
    
    if (error.status === 403) {
      // Insufficient scope - parse WWW-Authenticate header
      const wwwAuth = error.headers['www-authenticate'];
      const requiredScopes = parseScopes(wwwAuth);
      
      // Request new authorization with additional scopes
      console.log('Additional scopes required:', requiredScopes);
      // Initiate new auth flow with updated scopes
    }
    
    throw error;
  }
}
```

**Key Implementation Notes:**

1. **Base URL Derivation**: All OAuth URLs (callbacks, metadata endpoints) are derived from the incoming request context (`ctx.baseUrl`), making the system environment-agnostic and supporting multi-tenancy.

2. **OAuth Discovery Timing**: OAuth discovery and Dynamic Client Registration happen **once** when creating a connection, not on every proxy request. The discovered configuration is stored in the database and reused.

3. **Database Schema**: Uses Kysely's type-only schema definitions (TypeScript interfaces). Dialect is automatically determined from `DATABASE_URL` protocol (sqlite://, postgres://, mysql://). No dialect-specific schema code needed!

4. **Token Caching**: Downstream MCP tokens are cached in `downstreamTokens` table with automatic refresh to minimize repeated authorization flows.

**Key MCP OAuth Requirements:**

Based on the [MCP Authorization Spec](https://modelcontextprotocol.io/specification/draft/basic/authorization):

1. ✅ **PKCE Required** - All authorization code flows must use PKCE with S256
2. ✅ **Token Audience Binding** - Use RFC 8707 `resource` parameter for tokens
3. ✅ **Protected Resource Metadata** - Expose `/.well-known/oauth-protected-resource`
4. ✅ **Authorization Server Metadata** - Expose `/.well-known/oauth-authorization-server`
5. ✅ **Dynamic Client Registration** - Support RFC7591 for automatic client registration
6. ✅ **WWW-Authenticate Headers** - Return proper OAuth challenges with scope guidance
7. ✅ **Token Validation** - Never pass through tokens; always validate audience claims
8. ✅ **Scope Challenges** - Return `insufficient_scope` errors with required scopes
9. ✅ **Multi-Role Architecture** - Acts as Authorization Server, Resource Server, and OAuth Client
10. ✅ **Downstream OAuth Support** - Can connect to OAuth-enabled downstream MCPs with automatic discovery
11. ✅ **Request-Derived URLs** - All OAuth URLs derived from request context for portability
12. ✅ **One-Time Discovery** - OAuth discovery happens at connection creation, not at proxy time

#### 8. MCP Bindings: Protocol-Level Interfaces

MCP Bindings are a powerful abstraction that enables polymorphic tool implementations across different providers. Think of bindings as TypeScript interfaces, but for MCP tools—they define a contract that any MCP service can implement.

**Concept:**

A binding is a named set of tool signatures. If an MCP connection implements all the tools in a binding, it conforms to that binding type. This follows the "duck typing" principle: if it implements the right tools, it's the right type.

**Why Bindings Matter:**

1. **Provider Interchangeability**: Switch between Gmail, Outlook, or SendGrid without changing your application code
2. **Generic UIs**: Build a chat interface once, plug in any CHAT-compatible MCP provider
3. **Dependency Management**: Tools can depend on bindings instead of specific connections
4. **Marketplace Discovery**: Filter MCP apps by the bindings they implement

**Example Bindings:**

```typescript
// core/bindings.ts
import { z } from 'zod';

// CHAT Binding: Conversational messaging interface
export const CHAT_BINDING = {
  name: 'CHAT',
  version: '1.0.0',
  tools: {
    SEND_MESSAGE: {
      description: 'Send a message to a conversation',
      inputSchema: z.object({
        threadId: z.string(),
        content: z.string(),
        attachments: z.array(z.string()).optional(),
      }),
    },
    LIST_THREADS: {
      description: 'List all conversation threads',
      inputSchema: z.object({
        limit: z.number().optional(),
        offset: z.number().optional(),
      }),
    },
    GET_THREAD: {
      description: 'Get details of a specific thread',
      inputSchema: z.object({
        threadId: z.string(),
      }),
    },
    LIST_MESSAGES: {
      description: 'List messages in a thread',
      inputSchema: z.object({
        threadId: z.string(),
        limit: z.number().optional(),
      }),
    },
  },
};

// EMAIL Binding: Email sending and management
export const EMAIL_BINDING = {
  name: 'EMAIL',
  version: '1.0.0',
  tools: {
    SEND_EMAIL: {
      description: 'Send an email',
      inputSchema: z.object({
        to: z.array(z.string().email()),
        subject: z.string(),
        body: z.string(),
        attachments: z.array(z.string()).optional(),
      }),
    },
    LIST_EMAILS: {
      description: 'List emails in inbox',
      inputSchema: z.object({
        folder: z.string().optional(),
        limit: z.number().optional(),
      }),
    },
    GET_EMAIL: {
      description: 'Get a specific email',
      inputSchema: z.object({
        emailId: z.string(),
      }),
    },
  },
};

// STORAGE Binding: File storage operations
export const STORAGE_BINDING = {
  name: 'STORAGE',
  version: '1.0.0',
  tools: {
    UPLOAD_FILE: {
      description: 'Upload a file',
      inputSchema: z.object({
        path: z.string(),
        content: z.string(),
        contentType: z.string().optional(),
      }),
    },
    DOWNLOAD_FILE: {
      description: 'Download a file',
      inputSchema: z.object({
        path: z.string(),
      }),
    },
    LIST_FILES: {
      description: 'List files in a directory',
      inputSchema: z.object({
        path: z.string().optional(),
      }),
    },
    DELETE_FILE: {
      description: 'Delete a file',
      inputSchema: z.object({
        path: z.string(),
      }),
    },
  },
};
```

**Binding Detection:**

The Mesh automatically detects which bindings a connection implements:

```typescript
// core/binding-detector.ts
export function detectBindings(
  connection: MCPConnection
): string[] {
  const bindings: string[] = [];
  const toolNames = connection.tools?.map(t => t.name) || [];
  
  // Check each registered binding
  for (const binding of REGISTERED_BINDINGS) {
    const requiredTools = Object.keys(binding.tools);
    const hasAllTools = requiredTools.every(tool => 
      toolNames.includes(tool)
    );
    
    if (hasAllTools) {
      bindings.push(binding.name);
    }
  }
  
  return bindings;
}
```

**Using Bindings in Policies:**

Bindings don't affect policies directly. Policies grant access to specific tool names. The value of bindings is for **discovery and UI generation**, not authorization:

```typescript
// Policy grants access to specific tools (not bindings)
{
  "name": "Chat Access",
  "statements": [
    {
      "effect": "allow",
      "resource": "SEND_MESSAGE",  // Grant access to this specific tool
      "actions": ["execute"]
    },
    {
      "effect": "allow",
      "resource": "LIST_THREADS",  // Grant access to this tool
      "actions": ["execute"]
    }
  ]
}

// The Mesh automatically detects that connections providing these tools
// implement the CHAT binding, which helps UIs discover compatible providers
```

**Building Generic UIs with Bindings:**

```typescript
// Generic chat component that works with any CHAT binding provider
export function ChatInterface({ projectSlug }: { projectSlug: string }) {
  const { data: connections } = useConnections(projectSlug);
  
  // Find any connection that implements CHAT binding
  const chatProvider = connections?.find(conn => 
    conn.bindings?.includes('CHAT')
  );
  
  if (!chatProvider) {
    return <div>No chat provider connected</div>;
  }
  
  // Use the provider's tools through the binding interface
  const sendMessage = async (threadId: string, content: string) => {
    await mcpProxy.call(chatProvider.id, 'SEND_MESSAGE', {
      threadId,
      content,
    });
  };
  
  return <ChatUI onSendMessage={sendMessage} />;
}
```

**Marketplace Integration:**

Apps in the marketplace can declare which bindings they implement:

```typescript
// App metadata
{
  "id": "slack-mcp",
  "name": "Slack",
  "description": "Slack integration via MCP",
  "implements": ["CHAT"],
  "tools": [
    "SEND_MESSAGE",
    "LIST_THREADS",
    "GET_THREAD",
    "LIST_MESSAGES"
  ]
}
```

Users can filter apps by binding:

```typescript
POST /mcp/tools/MARKETPLACE_SEARCH
{
  "binding": "CHAT"
}
// Returns: [{ name: "Slack" }, { name: "Discord" }, { name: "Teams" }]
```

**Benefits of Bindings:**

1. **Abstraction**: Code against interfaces, not implementations
2. **Flexibility**: Swap providers without code changes
3. **Reusability**: Generic UI components work with multiple providers
4. **Discoverability**: Find compatible apps in marketplace
5. **Type Safety**: Binding schemas provide validation
6. **Composability**: Tools can depend on bindings, not specific connections

#### 8. Context Factory

The context factory creates MeshContext with [Kysely](https://kysely.dev) for database-agnostic access:

```typescript
// core/context-factory.ts
import { Kysely } from 'kysely';
import type { Database } from '../storage/types';

export interface MeshContextConfig {
  db: Kysely<Database>;           // Kysely instance (dialect-agnostic)
  auth: BetterAuthInstance;       // Better Auth instance
  encryption: {
    key: string;
  };
  observability: {
    tracer: Tracer;    // OpenTelemetry tracer
    meter: Meter;      // OpenTelemetry meter
  };
}

export function createMeshContextFactory(
  config: MeshContextConfig
): (c: Context) => Promise<MeshContext> {
  // Create storage adapters using Kysely (works with any dialect)
  const storage = {
    projects: new ProjectStorage(config.db),
    connections: new ConnectionStorage(config.db),
    policies: new PolicyStorage(config.db),
    roles: new RoleStorage(config.db),
    tokens: new AccessTokenStorage(config.db),
    tokenRevocations: new TokenRevocationStorage(config.db),
    teams: new TeamStorage(config.db),
    auditLogs: new AuditLogStorage(config.db),
  };
  
  const vault = new CredentialVault(config.encryption.key);
  
  // Return factory function
  return async (c: Context): Promise<MeshContext> => {
    // Extract API key from request
    const authHeader = c.req.header('Authorization');
    const key = authHeader?.replace('Bearer ', '');
    
    let auth: MeshContext['auth'] = {};
    if (key) {
      // Verify API key with Better Auth
      // https://www.better-auth.com/docs/plugins/api-key#verify-an-api-key
      const result = await config.auth.api.verifyApiKey({
        body: { key },
      });
      
      if (!result.valid) {
        throw new UnauthorizedError(result.error?.message || 'Invalid API key');
      }
      
      // Load user from database
      const user = await storage.users.findById(result.key.userId);
      
      auth = {
        user,
        apiKey: {
          id: result.key.id,
          name: result.key.name,
          userId: result.key.userId,
          permissions: result.key.permissions || {},
          metadata: result.key.metadata,
          remaining: result.key.remaining,
          expiresAt: result.key.expiresAt,
        },
      };
    }
    
    // Extract project from path (Kubernetes namespace concept)
    const projectSlug = extractProjectSlug(c.req.path);
    let project: MeshContext['project'] | undefined;
    if (projectSlug) {
      // Namespace-scoped (project-level) request
      project = await storage.projects.findBySlug(projectSlug);
      
      if (!project) {
        throw new NotFoundError('Project not found');
      }
      
      // Verify API key has project-related permissions
      if (auth.apiKey) {
        const hasProjectAccess = 
          auth.apiKey.permissions['mcp']?.some(tool => 
            tool.startsWith('PROJECT_')
          ) ||
          auth.apiKey.permissions[`project:${project.id}`]?.length > 0;
        
        if (!hasProjectAccess && auth.user?.role !== 'admin') {
          throw new UnauthorizedError(
            `API key does not have access to project: ${projectSlug}`
          );
        }
      }
    }
    
    // Derive base URL from request (for OAuth callbacks, metadata URLs, etc.)
    const url = new URL(c.req.url);
    const baseUrl = `${url.protocol}//${url.host}`;
    
    return {
      auth,
      project,
      storage,
      vault,
      auth: config.auth, // Better Auth instance
      access: new AccessControl(
        config.auth,                    // Better Auth instance for permission checks
        auth.user?.id,                  // User ID (for role-based permissions)
        undefined,                      // toolName (set later by defineTool)
        auth.apiKey?.permissions,       // Permissions from API key
        auth.user?.role,                // Role from user session
        undefined                       // connectionId (set when proxying to specific connection)
      ),
      db: config.db, // Kysely instance for direct queries
      tracer: config.observability.tracer,
      meter: config.observability.meter,
      baseUrl,
      metadata: {
        requestId: crypto.randomUUID(),
        timestamp: new Date(),
        userAgent: c.req.header('User-Agent'),
        ipAddress: c.req.header('CF-Connecting-IP') || c.req.header('X-Forwarded-For'),
      },
    };
  };
}
```

**Database Initialization with Kysely:**

Kysely allows you to specify the dialect once and write database-agnostic queries. The dialect is automatically determined from the `DATABASE_URL`:

```typescript
// database/index.ts
import { Kysely, PostgresDialect, SqliteDialect, MysqlDialect } from 'kysely';
import { Pool } from 'pg';
import Database from 'better-sqlite3';
import { createPool } from 'mysql2';
import type { Database as DatabaseSchema } from './types';

/**
 * Create Kysely instance with dialect determined from DATABASE_URL
 * https://kysely.dev/docs/getting-started
 */
export function createDatabase(databaseUrl: string): Kysely<DatabaseSchema> {
  const url = new URL(databaseUrl);
  const protocol = url.protocol.replace(':', '');

  // Determine dialect from DATABASE_URL
  switch (protocol) {
    case 'postgres':
    case 'postgresql': {
      const dialect = new PostgresDialect({
        pool: new Pool({
          connectionString: databaseUrl,
          max: 10,
        }),
      });
      return new Kysely<DatabaseSchema>({ dialect });
    }

    case 'sqlite':
    case 'file': {
      // Extract file path from URL
      const dbPath = url.pathname;
      const dialect = new SqliteDialect({
        database: new Database(dbPath),
      });
      return new Kysely<DatabaseSchema>({ dialect });
    }

    case 'mysql': {
      const dialect = new MysqlDialect({
        pool: createPool({
          uri: databaseUrl,
          connectionLimit: 10,
        }),
      });
      return new Kysely<DatabaseSchema>({ dialect });
    }

    default:
      throw new Error(`Unsupported database protocol: ${protocol}`);
  }
}

// Usage
const db = createDatabase(process.env.DATABASE_URL || 'file:./mesh.db');
```

**Better Auth with Kysely Adapter:**

Better Auth has a built-in Kysely adapter, making integration seamless:

```typescript
// auth/index.ts
import { betterAuth } from "better-auth";
import { apiKey } from "better-auth/plugins";
import { admin } from "better-auth/plugins";
import { kyselyAdapter } from "better-auth/adapters/kysely";
import { db } from '../database';

export const auth = betterAuth({
  database: kyselyAdapter(db, {
    // Kysely adapter automatically handles dialect differences!
    // No need to specify if it's SQLite, PostgreSQL, or MySQL
  }),
  
  plugins: [
    apiKey({
      permissions: {
        // Default permissions for newly created API keys
        defaultPermissions: {
          'mcp': ['PROJECT_LIST', 'PROJECT_GET'], // Organization-level tool access
        },
      },
    }),
    admin({
      defaultRole: "user",
      adminRoles: ["admin"],
    }),
  ],
});
```

**Storage Class Example (Database-Agnostic):**

Storage classes use Kysely's query builder, which works identically across all dialects:

```typescript
// storage/connection.ts
import { Kysely } from 'kysely';
import type { Database, MCPConnection } from './types';

export class ConnectionStorage {
  constructor(private db: Kysely<Database>) {}

  async findById(id: string): Promise<MCPConnection | null> {
    // This query works on SQLite, PostgreSQL, AND MySQL!
    return await this.db
      .selectFrom('connections')
      .selectAll()
      .where('id', '=', id)
      .executeTakeFirst() ?? null;
  }

  async list(projectId: string | null): Promise<MCPConnection[]> {
    let query = this.db.selectFrom('connections').selectAll();
    
    if (projectId) {
      query = query.where('projectId', '=', projectId);
    } else {
      query = query.where('projectId', 'is', null);
    }
    
    return await query.execute();
  }

  async create(data: Omit<MCPConnection, 'id' | 'createdAt' | 'updatedAt'>): Promise<MCPConnection> {
    return await this.db
      .insertInto('connections')
      .values({
        id: crypto.randomUUID(),
        ...data,
        createdAt: new Date(),
        updatedAt: new Date(),
      })
      .returningAll()
      .executeTakeFirstOrThrow();
  }

  async update(id: string, data: Partial<MCPConnection>): Promise<MCPConnection> {
    return await this.db
      .updateTable('connections')
      .set({ ...data, updatedAt: new Date() })
      .where('id', '=', id)
      .returningAll()
      .executeTakeFirstOrThrow();
  }

  async delete(id: string): Promise<void> {
    await this.db
      .deleteFrom('connections')
      .where('id', '=', id)
      .execute();
  }
}
```

#### 9. Tool Registration and Pipeline

```typescript
// api/index.ts
import { Hono } from 'hono';
import { createMeshContextFactory } from '../core/context-factory';
import { createDatabase } from '../database';
import { auth } from '../auth';
import { tracer, meter } from '../observability';
import * as ProjectTools from '../tools/project';
import * as ConnectionTools from '../tools/connection';

const app = new Hono();

// Initialize database with auto-detected dialect
const db = createDatabase(process.env.DATABASE_URL || 'file:./mesh.db');

// Create context factory
const createContext = createMeshContextFactory({
  db,
  auth,
  encryption: {
    key: process.env.ENCRYPTION_KEY!,
  },
  observability: {
    tracer,
    meter,
  },
});

// Register middleware
app.use('*', async (c, next) => {
  const ctx = await createContext(c);
  c.set('meshContext', ctx);
  await next();
});

// Tool execution handler
async function executeTool(
  c: Context,
  toolName: string,
  args: unknown
): Promise<unknown> {
  const ctx = c.get('meshContext') as MeshContext;
  
  // Find tool definition
  const tool = TOOL_REGISTRY.find(t => t.name === toolName);
  if (!tool) {
    throw new Error(`Unknown tool: ${toolName}`);
  }
  
  // Execute tool using defineTool's execute method
  // This handles: validation, authorization checking, logging
  const result = await tool.execute(args, ctx);
  
  // Verify authorization was checked (safety check)
  if (!ctx.access.granted()) {
    throw new Error(`SECURITY: Tool ${toolName} did not grant access`);
  }
  
  return result;
}

// Tool execution endpoint
app.post('/mcp/tools/:toolName', async (c) => {
  const toolName = c.req.param('toolName');
  const args = await c.req.json();
  
  const result = await executeTool(c, toolName, args);
  return c.json({ result });
});

// Tool registry - Array of all available tools
const TOOL_REGISTRY = [
  // Project Management
  ProjectTools.PROJECT_CREATE,
  ProjectTools.PROJECT_LIST,
  ProjectTools.PROJECT_GET,
  ProjectTools.PROJECT_UPDATE,
  ProjectTools.PROJECT_DELETE,
  
  // Connection Management
  ConnectionTools.CONNECTION_CREATE,
  ConnectionTools.CONNECTION_LIST,
  ConnectionTools.CONNECTION_GET,
  ConnectionTools.CONNECTION_UPDATE,
  ConnectionTools.CONNECTION_DELETE,
  ConnectionTools.CONNECTION_TEST,
  
  // Policy Management
  PolicyTools.POLICY_CREATE,
  PolicyTools.POLICY_LIST,
  PolicyTools.POLICY_UPDATE,
  PolicyTools.POLICY_DELETE,
  
  // Role Management
  RoleTools.ROLE_CREATE,
  RoleTools.ROLE_LIST,
  RoleTools.ROLE_UPDATE,
  RoleTools.ROLE_DELETE,
  
  // Token Management
  TokenTools.TOKEN_CREATE,
  TokenTools.TOKEN_LIST,
  TokenTools.TOKEN_REVOKE,
];
```

#### 10. Testing Strategy

The MeshContext abstraction and `defineTool` pattern enable comprehensive testing without HTTP servers:

```typescript
// tools/connection/create.test.ts
import { describe, it, expect } from 'bun:test';
import { CONNECTION_CREATE } from './create';
import { createMockContext } from '../../test-utils/mock-context';

describe('CONNECTION_CREATE', () => {
  it('creates connection when authorized', async () => {
    // Mock storage adapters
    const mockStorageAdapters = {
      connections: {
        create: async (data) => ({ 
          id: 'conn_123', 
          status: 'active',
          createdAt: new Date(),
          ...data 
        }),
      },
      policies: {
        evaluate: async () => true, // User is authorized
      },
      auditLogs: {
        log: async () => {},
      },
    };
    
    const ctx = createMockContext({
      auth: { user: { id: 'user_abc' } },
      project: { id: 'proj_xyz', slug: 'test' },
      storage: mockStorageAdapters,
    });
    
    // Call tool.execute() instead of calling handler directly
    const result = await CONNECTION_CREATE.execute({
      name: 'Test Connection',
      connection: { type: 'HTTP', url: 'https://example.com' },
    }, ctx);
    
    expect(result.id).toBe('conn_123');
    expect(result.name).toBe('Test Connection');
    expect(ctx.access.granted()).toBe(true);
  });
  
  it('throws when not authorized', async () => {
    const mockStorageAdapters = {
      policies: {
        evaluate: async () => false, // User is NOT authorized
      },
      auditLogs: {
        log: async () => {},
      },
    };
    
    const ctx = createMockContext({
      auth: { user: { id: 'user_abc' } },
      project: { id: 'proj_xyz', slug: 'test' },
      storage: mockStorageAdapters,
    });
    
    await expect(
      CONNECTION_CREATE.execute({ 
        name: 'Test', 
        connection: { type: 'HTTP', url: 'https://example.com' } 
      }, ctx)
    ).rejects.toThrow('Not allowed to execute CONNECTION_CREATE');
  });
  
  it('automatically logs audit trail', async () => {
    const auditLogSpy = vi.fn();
    const mockStorageAdapters = {
      connections: {
        create: async (data) => ({ 
          id: 'conn_123', 
          status: 'active',
          createdAt: new Date(),
          ...data 
        }),
      },
      policies: {
        evaluate: async () => true,
      },
      auditLogs: {
        log: auditLogSpy, // Spy on audit logging
      },
    };
    
    const ctx = createMockContext({
      auth: { user: { id: 'user_abc' } },
      project: { id: 'proj_xyz', slug: 'test' },
      storage: mockStorageAdapters,
    });
    
    await CONNECTION_CREATE.execute({ 
      name: 'Test',
      connection: { type: 'HTTP', url: 'https://example.com' } 
    }, ctx);
    
    // Verify audit log was created automatically
    expect(auditLogSpy).toHaveBeenCalledWith(
      expect.objectContaining({
        toolName: 'CONNECTION_CREATE',
        allowed: true,
        userId: 'user_abc',
        projectId: 'proj_xyz',
      })
    );
  });
});
```

### Benefits of This Architecture

1. **MCP Native**: Uses JSON Schema for tool definitions, aligning with MCP protocol standards
2. **Declarative Tool Definition**: `defineTool` provides self-documenting tool definitions with automatic logging
3. **No Duplicate Validation**: Leverages MCP's built-in validation instead of adding extra layers
4. **Testability**: Tools can be unit tested without spinning up HTTP servers or databases
5. **Flexibility**: Kysely provides true database-agnostic queries (SQLite, PostgreSQL, MySQL) with dialect specified once
6. **Security**:
   - Explicit authorization checks with clean `ctx.access.check()` API prevent accidental bypass
   - Separate `.grant()` method for intentional admin overrides (clear audit trail)
   - [Better Auth Admin plugin](https://www.better-auth.com/docs/plugins/admin) for role-based permissions
   - [Better Auth API Key plugin](https://www.better-auth.com/docs/plugins/api-key) for key-based permissions
   - [Better Auth MCP plugin](https://www.better-auth.com/docs/plugins/mcp) for OAuth 2.1 compliance
   - UUID-based connection permissions prevent name-collision attacks
   - Resource-based permission model: `{ [resource]: [actions...] }`
   - Unified permission checking via `auth.api.userHasPermission`
7. **Maintainability**: Clear boundaries between layers (API → Tools → Storage)
8. **Reusability**: Tools can be called from HTTP API, CLI, tests, or other tools
9. **Type Safety**: Strong TypeScript interfaces throughout with Kysely's type-safe queries
10. **Clear Naming**:

- `core/` contains cross-cutting concerns (context, factory, access control, define-tool)
- `storage/types.ts` defines Kysely database schema
- `storage/*.ts` implements storage classes using Kysely

### Architecture Naming Clarifications

To avoid confusion and maintain clean separation of concerns:

**Tool Definition Pattern:**

- **`defineTool`** (`core/define-tool.ts`): Declarative tool definition function
  - Takes: `name`, `description`, `inputSchema` (JSON Schema), `handler` function
  - Returns: Tool definition with `execute` method
  - Automatically handles: authorization checking, audit logging
  - Handler signature: `async (input: TInput, ctx: MeshContext) => Promise<TOutput>`
  - Validation: Handled by MCP protocol layer (no duplicate validation needed)

Benefits:

- MCP native - uses standard JSON Schema format
- No duplicate validation - leverages protocol layer
- Co-located schema and business logic
- Self-documenting (JSON Schema serves as documentation)
- Easy to test (just call `tool.execute()`)
- Tool definitions can be exposed directly via MCP protocol

**Access Control API:**

- **`ctx.access.check()`** - Check permissions for current tool (from `ctx.toolName`), grants access if allowed
- **`ctx.access.check("conn_<UUID>")`** - Check if user has access to specific connection
- **`ctx.access.check("TOOL_NAME")`** - Check if user has access to specific tool
- **`ctx.access.check("TOOL1", "TOOL2")`** - Check if user has access to ANY of the tools (OR logic)
- **`ctx.access.grant()`** - Unconditionally grant access (for admin overrides or custom validation)
- **`ctx.access.granted()`** - Check if access was granted

**Permission Checking Process:**

1. **Better Auth Integration**: Uses `auth.api.userHasPermission` from [Better Auth Admin plugin](https://www.better-auth.com/docs/plugins/admin#access-control)
2. **Dual Source Support**: Checks permissions from both:
   - **Role-based** (from Better Auth Admin plugin): User's role → permissions
   - **API Key-based** (from Better Auth API Key plugin): API key → permissions
3. **Permission Format**: `{ [resource]: [actions...] }`
   - Resources: connection IDs (`conn_<UUID>`), tool names, or custom resources
   - Actions: Array of allowed actions (use `['*']` for wildcard)
4. **Fallback**: If Better Auth API is unavailable, falls back to manual permission checking

**Behavior:**

- `.check()` performs permission validation and calls `.grant()` internally if allowed
- `.grant()` simply sets the granted flag to `true` without any permission checks
- The tool name is automatically set by `defineTool` wrapper, so authorization is contextual
- Use `.check()` for standard permission validation
- Use `.grant()` only for admin overrides or after custom validation logic
- Throws `ForbiddenError` if access is denied

**Context-Related Files:**

- `core/mesh-context.ts` - The core MeshContext interface definition
- `core/context-factory.ts` - Factory function that creates MeshContext instances
- `core/access-control.ts` - Access control helper for authorization tracking
- `api/middlewares/inject-context.ts` - Hono middleware that injects MeshContext into requests

The `core/` folder contains the heart of the application: the context abstraction and its factory. The middleware simply uses the factory to inject context into HTTP requests.

**Storage Pattern: Ports & Adapters**

We follow the Ports & Adapters pattern (Hexagonal Architecture):

- **Ports** (`storage/ports.ts`): Define the contracts/interfaces that the business logic depends on
- **Adapters** (`storage/adapters/`): Implement those contracts for specific databases

This pattern:

- Makes the business logic (tools) database-agnostic
- Allows easy testing with mock adapters
- Enables switching databases without changing tool code
- Follows dependency inversion principle (depend on abstractions, not implementations)

**Why "Adapter" instead of "Implementation"?**

The term "adapter" is more precise and idiomatic in software architecture:

- "Adapter" implies converting one interface to another (database → port interface)
- "Implementation" is too generic and could refer to any code
- "Adapter" clearly signals the Ports & Adapters pattern
- Industry-standard naming that developers recognize

**MCP Bindings: Protocol-Level Interfaces**

Bindings provide an abstraction layer on top of MCP connections:

- **Bindings** (`core/bindings.ts`): Define standard tool contracts (CHAT, EMAIL, STORAGE, etc.)
- **Binding Detection** (`core/binding-detector.ts`): Automatically detect which bindings a connection implements
- **Polymorphism**: Multiple providers (Slack, Discord, Teams) can all implement the same CHAT binding
- **Generic UIs**: Build UI components that work with any provider implementing a specific binding

This enables:

- Swapping providers without code changes (Gmail → Outlook → SendGrid)
- Building reusable UI components that work with any compatible provider
- Filtering marketplace apps by binding type
- Policy statements that grant access to any connection implementing a binding

**JWT Security & Key Management:**

Hardened JWT implementation with enterprise-grade security:

- **Token Validation** (`auth/jwt-issuer.ts`): Comprehensive JWT verification with multiple security checks
  - Issuer validation against configured base URL
  - Clock skew tolerance (60s) for time synchronization
  - Not-before (`nbf`) validation to prevent premature token use
  - Strict expiration (`exp`) enforcement without grace periods
  - Unique JWT ID (`jti`) for revocation tracking
- **Key Rotation** (`auth/jwks-endpoint.ts`): JWKS support for seamless key rotation
  - Multiple active keys identified by `kid` (Key ID)
  - RS256 algorithm with asymmetric keys
  - Public keys exposed via `/.well-known/jwks.json`
  - Zero-downtime key rotation
- **Token Revocation** (`storage/ports.ts`): Instant token revocation via jti blacklist
  - Check against revocation list on every request
  - Automatic cleanup of expired revocations
  - No waiting for token expiry
- **Stable Audience**: Uses immutable `project:<projectId>` format instead of mutable slugs
  - Prevents audience bypass via slug changes
  - Project slug included as separate claim for convenience

Security Benefits:

- Prevents token reuse across systems (issuer validation)
- Handles clock drift gracefully (60s tolerance)
- Enables instant revocation without waiting for expiry
- Supports key rotation without invalidating existing tokens
- Uses stable immutable identifiers for authorization

---

## Technical Architecture

### Runtime & Technology Stack

**Runtime Environment:**

- **Language**: TypeScript on Bun runtime
- **Deployment**: Self-hosted via standalone binary or Docker
- **Supported Platforms**: Linux, macOS, Windows (via WSL2)

**Core Dependencies:**

- **Web Framework**: Hono (lightweight, edge-compatible)
- **Database**: SQLite via `better-sqlite3` (zero-config default), PostgreSQL, or MySQL
- **Query Builder**: Kysely (type-safe, database-agnostic)
- **Authentication**: Better Auth (with Kysely adapter)
- **Validation**: Zod
- **Observability**: OpenTelemetry (tracing and metrics)

**Getting Started (Zero Config):**

```bash
# Clone the repository
git clone https://github.com/decocms/admin.git
cd admin/apps/mesh

# Install dependencies
bun install

# Start the server (SQLite database created automatically)
bun run start
```

That's it! The Mesh will automatically:

- Create a local SQLite database at `./data/mesh.db`
- Run all necessary migrations
- Start the server on `http://localhost:3000`
- Expose all management features via MCP protocol at `/mcp`

**Optional Configuration:**

Only one environment variable is supported:

```bash
# Optional: Use PostgreSQL instead of SQLite
DATABASE_URL=postgresql://user:pass@host:5432/dbname
```

All other configuration (OAuth, SAML, etc.) is done via `auth-config.json`:

```bash
# Create optional auth configuration
cat > auth-config.json << 'EOF'
{
  "socialProviders": {
    "google": {
      "clientId": "your-google-client-id",
      "clientSecret": "your-google-client-secret"
    },
    "github": {
      "clientId": "your-github-client-id", 
      "clientSecret": "your-github-client-secret"
    }
  },
  "saml": {
    "enabled": true,
    "providers": [
      {
        "name": "Okta",
        "entryPoint": "https://your-org.okta.com/app/...",
        "issuer": "http://www.okta.com/...",
        "cert": "-----BEGIN CERTIFICATE-----..."
      }
    ]
  }
}
EOF

# Restart to apply auth configuration
bun run start
```

### Database Model

**Core Entities:**

```typescript
// Users & Authentication
interface User {
  id: string;
  email: string;
  name: string;
  createdAt: Date;
  updatedAt: Date;
}

interface Session {
  id: string;
  userId: string;
  expiresAt: Date;
  token: string;
}

// Project Management (Namespace-scoped, like Kubernetes namespaces)
// The database itself represents the workspace/organization boundary
interface Project {
  id: string;
  name: string;
  slug: string; // URL-safe identifier (e.g., "my-project"), unique within workspace
  ownerId: string;
  description?: string;
  createdAt: Date;
  updatedAt: Date;
}

interface ProjectMember {
  id: string;
  projectId: string;
  userId: string;
  roleIds: string[]; // Array of role IDs
  createdAt: Date;
}

// Team Management (within a project)
interface Team {
  id: string;
  projectId: string;
  name: string;
  ownerId: string;
  createdAt: Date;
}

interface TeamMember {
  id: string;
  teamId: string;
  userId: string;
  roleIds: string[]; // Array of role IDs
  createdAt: Date;
}

// MCP Connections (based on MCPConnection model)
type ConnectionType = 'HTTP' | 'SSE' | 'Websocket';

interface MCPConnection {
  id: string;
  projectId: string | null; // Null = organization-scoped (cluster-level), Set = project-scoped (namespace-level)
  teamId?: string; // Optional: scope to specific team
  createdById: string;
  name: string;
  description?: string;
  icon?: string;
  appName?: string;
  appId?: string;
  
  // Connection configuration (discriminated union)
  connection: 
    | { type: 'HTTP'; url: string; token?: string }
    | { type: 'SSE'; url: string; token?: string; headers?: Record<string, string> }
    | { type: 'Websocket'; url: string; token?: string };
  
  // OAuth configuration for downstream MCP (if the downstream MCP supports OAuth)
  oauthConfig?: {
    // Discovered from downstream MCP's /.well-known/oauth-protected-resource
    authorizationEndpoint: string;
    tokenEndpoint: string;
    introspectionEndpoint?: string;
    
    // OAuth client credentials for this connection (obtained via Dynamic Client Registration or manual config)
    clientId: string;
    clientSecret?: string; // Encrypted in vault
    
    // Scopes required for this connection
    scopes: string[];
    
    // Whether to use user-specific tokens (authorization_code) or service tokens (client_credentials)
    grantType: 'authorization_code' | 'client_credentials';
  };
  
  metadata?: Record<string, any>;
  tools?: Array<{
    name: string;
    description?: string;
    inputSchema: object;
    outputSchema?: object;
  }>;
  
  // Detected bindings that this connection implements
  bindings?: string[]; // e.g., ['CHAT', 'EMAIL']
  
  // Scope indicator (derived from projectId, like Kubernetes resource scope)
  scope: 'organization' | 'project'; // 'organization' if projectId is null, 'project' otherwise
  
  status: 'active' | 'inactive' | 'error';
  createdAt: Date;
  updatedAt: Date;
}

// Better Auth-based Access Control
// Based on: https://www.better-auth.com/docs/plugins/admin#access-control

// Permission: Resource-based permission (Better Auth format)
// https://www.better-auth.com/docs/plugins/api-key#permissions
// Format: { [resource]: [tools...] }
// Resources can be:
//   - Organization-level: "mcp" → list of organization-scoped tools (PROJECT_CREATE, PROJECT_LIST, etc.)
//   - Connection-specific: "conn_<UUID>" → list of connection-specific tools (SEND_MESSAGE, LIST_THREADS, etc.)
//   - Project-specific: "project:<projectId>" → list of project-level permissions
// Example: {
//   "mcp": ["PROJECT_CREATE", "PROJECT_LIST", "PROJECT_GET"],
//   "conn_123e4567-e89b-12d3-a456-426614174000": ["SEND_MESSAGE", "LIST_THREADS"]
// }
type Permission = Record<string, string[]>;

// Role: Named set of permissions (Better Auth compatible)
interface Role {
  id: string;
  projectId: string;
  name: string;
  description?: string;
  permissions: Permission; // e.g., { "conn_<UUID>": ["SEND_MESSAGE", "LIST_THREADS"] }
  createdAt: Date;
  updatedAt: Date;
}

// User extends Better Auth User with role field
interface User {
  id: string;
  email: string;
  name: string;
  role: string; // Role name (e.g., "admin", "user", "developer")
  // Better Auth handles other fields (password, sessions, etc.)
}

// API Key (Better Auth API Key Plugin)
// Based on: https://www.better-auth.com/docs/plugins/api-key
interface ApiKey {
  id: string;
  projectId: string;
  userId: string; // The user who created this key
  name: string;
  token: string; // Hashed API key
  permissions: Permission; // e.g., { "conn_<UUID>": ["SEND_MESSAGE"] }
  expiresAt: Date | null;
  createdAt: Date;
  updatedAt: Date;
  // Better Auth handles: enabled, ipAddress restrictions, etc.
}

// Audit Logs
interface AuditLog {
  id: string;
  projectId: string;
  userId?: string;
  accessTokenId?: string;
  connectionId?: string;
  toolName: string; // The tool that was called
  allowed: boolean; // Whether access was granted
  timestamp: Date;
  requestMetadata: object;
  responseStatus?: number;
  denyReason?: string;
}
```

**Database Technology:**

- **Default**: SQLite via `better-sqlite3` (zero configuration required)
- **Optional**: PostgreSQL or MySQL (for larger deployments or multi-instance setups)
- **Migrations**: Managed via Kysely's migration system
- **Dialect Auto-Detection**: Automatically determined from `DATABASE_URL` protocol

**Why SQLite?**

- Zero configuration - works out of the box
- Perfect for self-hosted single-instance deployments
- Excellent performance with `better-sqlite3`
- Simple backup and restore (just copy the `.db` file)
- Upgrade to PostgreSQL or MySQL anytime without code changes (Kysely handles it!)

**Why Kysely?**

- **True Database Agnostic**: Write queries once, run anywhere (SQLite, PostgreSQL, MySQL)
- **Single Dialect Specification**: Set dialect once at initialization, not in every schema file
- **Type-Safe**: Full TypeScript inference for queries and results
- **Better Auth Compatible**: Native Kysely adapter available
- **Simple**: Type-only schema definitions (just TypeScript interfaces)

### Authentication System

**Better Auth Integration:**

MCP Mesh uses Better Auth for flexible authentication with multiple providers. All authentication configuration is done via an optional `auth-config.json` file—no environment variables needed!

**Supported Auth Methods:**

1. **Email/Password**: Enabled by default
2. **OAuth Providers**: Google, GitHub, Microsoft, Generic OAuth 2.0
3. **SSO (SAML)**: Enterprise SSO support

**Configuration via `auth-config.json`:**

The file accepts a partial Better Auth configuration object, allowing you to enable only the providers you need:

```json
{
  "emailAndPassword": {
    "enabled": true
  },
  "socialProviders": {
    "google": {
      "clientId": "your-google-client-id",
      "clientSecret": "your-google-client-secret"
    },
    "github": {
      "clientId": "your-github-client-id",
      "clientSecret": "your-github-client-secret"
    },
    "microsoft": {
      "clientId": "your-microsoft-client-id",
      "clientSecret": "your-microsoft-client-secret"
    }
  },
  "saml": {
    "enabled": true,
    "providers": [
      {
        "name": "Okta",
        "entryPoint": "https://your-org.okta.com/app/...",
        "issuer": "http://www.okta.com/...",
        "cert": "-----BEGIN CERTIFICATE-----\n...\n-----END CERTIFICATE-----"
      }
    ]
  }
}
```

**Implementation:**

```typescript
import { betterAuth } from "better-auth";
import { kyselyAdapter } from "better-auth/adapters/kysely";
import { createDatabase } from "./database"; // Our Kysely factory
import { readFileSync, existsSync } from "fs";

// Load optional auth configuration
let authConfig = { emailAndPassword: { enabled: true } };
if (existsSync("./auth-config.json")) {
  authConfig = JSON.parse(readFileSync("./auth-config.json", "utf-8"));
}

// Initialize database with Kysely (auto-detects dialect from DATABASE_URL)
const databaseUrl = process.env.DATABASE_URL || "file:./data/mesh.db";
const db = createDatabase(databaseUrl);

export const auth = betterAuth({
  database: kyselyAdapter(db), // Better Auth's Kysely adapter
  ...authConfig, // Spread user configuration
});

// Export Kysely instance for application use
export { db };
```

**The `createDatabase` function automatically detects the database type:**

```typescript
// database/index.ts
import { Kysely, PostgresDialect, SqliteDialect, MysqlDialect } from 'kysely';
import { Pool } from 'pg';
import Database from 'better-sqlite3';
import { createPool } from 'mysql2';
import type { Database as DatabaseSchema } from './types';

export function createDatabase(databaseUrl: string): Kysely<DatabaseSchema> {
  const url = new URL(databaseUrl);
  const protocol = url.protocol.replace(':', '');

  switch (protocol) {
    case 'postgres':
    case 'postgresql':
      return new Kysely<DatabaseSchema>({
        dialect: new PostgresDialect({
          pool: new Pool({ connectionString: databaseUrl, max: 10 }),
        }),
      });

    case 'sqlite':
    case 'file':
      return new Kysely<DatabaseSchema>({
        dialect: new SqliteDialect({
          database: new Database(url.pathname),
        }),
      });

    case 'mysql':
      return new Kysely<DatabaseSchema>({
        dialect: new MysqlDialect({
          pool: createPool({ uri: databaseUrl, connectionLimit: 10 }),
        }),
      });

    default:
      throw new Error(`Unsupported database protocol: ${protocol}`);
  }
}
```

### Core APIs (MCP Tools)

**MCP-Native API Architecture:**

The Mesh uses a hierarchical namespace structure where all operations are scoped to projects:

**Root-Level APIs** (`/mcp`) - Project Management:

```
POST /mcp/tools/{TOOL_NAME}
Authorization: Bearer <session-token>

// Used for managing projects themselves
```

**Tool Execution API:**

```
POST /mcp/tools/{TOOL_NAME}
Authorization: Bearer <api-key>

// Used for all tool operations (connections, policies, teams, etc.)
// Connection IDs are globally unique UUIDs, no project prefix needed in URL
```

**API Key Permissions:**

Better Auth API keys include permissions that determine which connections and tools can be accessed:

```typescript
interface MeshTokenPayload {
  // Standard JWT claims (RFC 7519)
  sub: string;           // Subject: Token ID or User ID
  iss: string;           // Issuer: Mesh instance base URL (e.g., "https://mesh.example.com")
  iat: number;           // Issued at: Unix timestamp
  exp: number;           // Expiration: Unix timestamp
  nbf: number;           // Not before: Unix timestamp (prevents premature use)
  aud: string;           // Audience: Stable immutable identifier
                         //   - Workspace token: "workspace" (database-level, projectId is null)
                         //   - Project token: "project:proj_abc123" (namespace-level)
  jti: string;           // JWT ID: Unique identifier for revocation tracking
  
  // Mesh-specific claims (organization is implicit via database connection)
  projectId?: string;       // Project ID (e.g., "proj_abc123") - null for workspace tokens
  projectSlug?: string;     // Project slug (e.g., "my-project") - for convenience, null for workspace tokens
  userId?: string;          // User ID (if user token)
  apiKeyId?: string;        // API Key ID (if API key token)
  role?: string;            // User role (e.g., "admin", "user", "developer")
  permissions?: Permission; // Better Auth permissions: { connectionId: ["tool1", "tool2"] }
}
```

**Built-in Management Tools:**

#### Project Management (Namespace-Scoped, Organization-Level: `/mcp`)

**PROJECT_CREATE**

```typescript
// Create a new project (namespace) in the organization
POST /mcp/tools/PROJECT_CREATE
Authorization: Bearer <organization-token>
{
  "name": "My Project",
  "slug": "my-project", // URL-safe, unique within organization
  "description": "My awesome project"
}
// Returns: { 
//   id: "proj_abc123", 
//   slug: "my-project", 
//   name: "My Project"
// }
```

**PROJECT_LIST**

```typescript
// List all projects user has access to
POST /mcp/tools/PROJECT_LIST
Authorization: Bearer <session-token>
{}
// Returns: { projects: [...] }
```

**PROJECT_GET**

```typescript
// Get project details
POST /mcp/tools/PROJECT_GET
Authorization: Bearer <session-token>
{
  "slug": "my-project" // or "id": "proj_abc123"
}
// Returns: { id, slug, name, description, ... }
```

**PROJECT_UPDATE**

```typescript
// Update project
POST /mcp/tools/PROJECT_UPDATE
Authorization: Bearer <session-token>
{
  "slug": "my-project",
  "name": "Updated Name",
  "description": "Updated description"
}
```

**PROJECT_DELETE**

```typescript
// Delete project
POST /mcp/tools/PROJECT_DELETE
Authorization: Bearer <session-token>
{
  "slug": "my-project"
}
```

**PROJECT_MEMBER_ADD**

```typescript
// Add member to project
POST /mcp/tools/PROJECT_MEMBER_ADD
Authorization: Bearer <session-token>
{
  "projectSlug": "my-project",
  "userId": "user_abc",
  "roleIds": ["role_789"]
}
```

**PROJECT_MEMBER_REMOVE**

```typescript
// Remove member from project
POST /mcp/tools/PROJECT_MEMBER_REMOVE
Authorization: Bearer <session-token>
{
  "projectSlug": "my-project",
  "userId": "user_abc"
}
```

---

#### Connection Management

Connections can be created at two levels (like Kubernetes resources):

- **Organization-scoped** (cluster-level): Shared across all projects when `projectId: null` (via `/mcp`)
- **Project-scoped** (namespace-level): Isolated to a single project when `projectId` is set (via `/:project/mcp`)

**CONNECTION_CREATE (Organization-Scoped / Cluster-Level)**

```typescript
// Create an organization-wide shared MCP connection (like a Kubernetes cluster-scoped resource)
POST /mcp/tools/CONNECTION_CREATE
Authorization: Bearer <organization-token>
{
  "name": "Company Slack",
  "description": "Slack integration shared across all projects",
  "icon": "https://...",
  "projectId": null, // null = organization-scoped (available to all projects)
  "connection": {
    "type": "HTTP",
    "url": "https://mcp.slack.com/mcp",
    "token": "slack-secret-token-XPTO"
  },
  "metadata": {}
}
// Returns: { 
//   id: "conn_abc123", 
//   name: "Company Slack", 
//   scope: "organization",
//   projectId: null,
//   status: "active" 
// }
```

**CONNECTION_CREATE (Project-Scoped)**

```typescript
// Create a project-specific MCP connection
POST /my-project/mcp/tools/CONNECTION_CREATE
Authorization: Bearer <project-token with aud: "project:proj_abc">
{
  "name": "Project Database",
  "description": "Database connection for this project only",
  "icon": "https://...",
  "projectId": "proj_abc", // Optional: automatically inferred from context
  "connection": {
    "type": "HTTP",
    "url": "https://mcp.postgres.com/mcp",
    "token": "postgres-secret-token-XPTO"
  },
  "metadata": {}
}
// Returns: { 
//   id: "conn_xyz789", 
//   name: "Project Database", 
//   scope: "project",
//   status: "active" 
// }
```

**CONNECTION_LIST**

```typescript
// List all connections available to this project
// Includes both project-scoped AND organization-scoped (shared) connections
POST /my-project/mcp/tools/CONNECTION_LIST
Authorization: Bearer <project-token>
{
  "scope": "all", // Options: "all" (default), "project", "organization"
  "teamId": "team_xyz" // Optional filter
}
// Returns: { 
//   connections: [
//     { id: "conn_abc123", name: "Company Slack", scope: "organization", projectId: null, ... },
//     { id: "conn_xyz789", name: "Project Database", scope: "project", projectId: "proj_abc", ... }
//   ] 
// }
```

```typescript
// List only organization-scoped connections (cluster-level)
POST /mcp/tools/CONNECTION_LIST
Authorization: Bearer <organization-token>
{
  "scope": "organization"
}
// Returns: { connections: [...] } // Only organization-level shared connections
```

**CONNECTION_GET**

```typescript
// Get connection details
POST /my-project/mcp/tools/CONNECTION_GET
Authorization: Bearer <project-token>
{
  "id": "conn_abc123"
}
// Returns: { id, name, description, connection, tools, status, ... }
```

**CONNECTION_UPDATE**

```typescript
// Update connection
POST /my-project/mcp/tools/CONNECTION_UPDATE
Authorization: Bearer <project-token>
{
  "id": "conn_abc123",
  "name": "Updated Gmail",
  "status": "active"
}
```

**CONNECTION_DELETE**

```typescript
// Delete connection
POST /my-project/mcp/tools/CONNECTION_DELETE
Authorization: Bearer <project-token>
{
  "id": "conn_abc123"
}
```

**CONNECTION_TEST**

```typescript
// Test connection health
POST /my-project/mcp/tools/CONNECTION_TEST
Authorization: Bearer <project-token>
{
  "id": "conn_abc123"
}
// Returns: { healthy: true, latencyMs: 45, availableTools: [...] }
```

**Multi-Level Scoping Benefits (Kubernetes-Inspired Model):**

The Mesh supports two levels of connection scoping, similar to Kubernetes resources:

| Scope | K8s Equivalent | `projectId` Value | Location | Use Case | Example |
|-------|----------------|-------------------|----------|----------|---------|
| **Organization** | Cluster-scoped | `null` | `/mcp` | Organization-wide integrations shared across all projects | Slack, email, HR systems, company calendar |
| **Project** | Namespace-scoped | `"proj_abc"` | `/:project/mcp` | Project-specific integrations with sensitive data | Project database, staging environment, project-specific APIs |

**Key Benefits:**

1. **Cost Efficiency**: Connect once to shared services (Slack, Gmail) at organization-level instead of per-project
2. **Centralized Management**: Update organization-wide credentials in one place
3. **Flexibility**: Mix and match organization-level and project-level connections as needed
4. **Security**: Keep sensitive project credentials isolated from other projects
5. **Inheritance**: Projects automatically get access to organization-level connections plus their own

**Access Pattern:**

```typescript
// When calling CONNECTION_LIST from a project context:
// Returns BOTH organization-scoped AND project-scoped connections
const connections = await CONNECTION_LIST({ scope: 'all' });

// Result:
// [
//   { id: "conn_1", name: "Company Slack", scope: "organization", projectId: null, ... },
//   { id: "conn_2", name: "Company Gmail", scope: "organization", projectId: null, ... },
//   { id: "conn_3", name: "Project DB", scope: "project", projectId: "proj_abc", ... }
// ]
```

**Authorization:**

- Organization-scoped connections: Require organization-level permissions (checked at database level)
- Project-scoped connections: Require project-level permissions
- Projects can READ organization-level connections but cannot DELETE them
- Only organization admins can manage organization-level connections

---

#### Policy & Access Control Management (Project-Scoped: `/:project/mcp`)

**POLICY_CREATE**

```typescript
// Create a new policy
POST /my-project/mcp/tools/POLICY_CREATE
Authorization: Bearer <project-token>
{
  "name": "Gmail Send Only",
  "description": "Allow only sending emails",
  "statements": [
    {
      "effect": "allow",
      "resource": "SEND_EMAIL",
      "matchCondition": {
        "resource": "is_connection",
        "connectionId": "conn_abc123"
      }
    },
    {
      "effect": "deny",
      "resource": "DELETE_*"
    }
  ]
}
// Returns: { id: "policy_123", name: "Gmail Send Only" }
```

**POLICY_LIST**

```typescript
// List all policies
POST /my-project/mcp/tools/POLICY_LIST
Authorization: Bearer <project-token>
{}
```

**POLICY_UPDATE**

```typescript
// Update policy statements
POST /my-project/mcp/tools/POLICY_UPDATE
Authorization: Bearer <project-token>
{
  "id": "policy_123",
  "statements": [...]
}
```

**POLICY_DELETE**

```typescript
// Delete policy
POST /my-project/mcp/tools/POLICY_DELETE
Authorization: Bearer <project-token>
{
  "id": "policy_123"
}
```

**ROLE_CREATE**

```typescript
// Create a role (set of policies)
POST /my-project/mcp/tools/ROLE_CREATE
Authorization: Bearer <project-token>
{
  "name": "Email Manager",
  "description": "Can manage email operations",
  "policyIds": ["policy_123", "policy_456"]
}
// Returns: { id: "role_789", name: "Email Manager" }
```

**ROLE_LIST**

```typescript
// List all roles
POST /my-project/mcp/tools/ROLE_LIST
Authorization: Bearer <project-token>
{}
```

**ROLE_UPDATE**

```typescript
// Update role
POST /my-project/mcp/tools/ROLE_UPDATE
Authorization: Bearer <project-token>
{
  "id": "role_789",
  "policyIds": ["policy_123", "policy_456", "policy_789"]
}
```

**ROLE_DELETE**

```typescript
// Delete role
POST /my-project/mcp/tools/ROLE_DELETE
Authorization: Bearer <project-token>
{
  "id": "role_789"
}
```

#### Access Token Management (Project-Scoped: `/:project/mcp`)

**TOKEN_CREATE**

```typescript
// Create access token with policies
POST /my-project/mcp/tools/TOKEN_CREATE
Authorization: Bearer <project-token>
{
  "name": "CI/CD Pipeline Token",
  "policyIds": ["policy_123"],
  "expiresIn": "90d" // or null for no expiration
}
// Returns: { 
//   id: "token_xyz789", 
//   token: "mesh_eyJhbGciOiJIUzI1NiIs...", // Has aud: "my-project"
//   expiresAt: "2025-01-26T00:00:00Z"
// }
```

**TOKEN_LIST**

```typescript
// List all tokens
POST /my-project/mcp/tools/TOKEN_LIST
Authorization: Bearer <project-token>
{
  "includeRevoked": false
}
```

**TOKEN_REVOKE**

```typescript
// Revoke a token
POST /my-project/mcp/tools/TOKEN_REVOKE
Authorization: Bearer <project-token>
{
  "id": "token_xyz789"
}
```

#### Team Management (Project-Scoped: `/:project/mcp`)

**TEAM_CREATE**

```typescript
// Create a new team
POST /my-project/mcp/tools/TEAM_CREATE
Authorization: Bearer <project-token>
{
  "name": "Engineering"
}
```

**TEAM_LIST**

```typescript
// List teams
POST /my-project/mcp/tools/TEAM_LIST
Authorization: Bearer <project-token>
{}
```

**TEAM_MEMBER_ADD**

```typescript
// Add member to team
POST /my-project/mcp/tools/TEAM_MEMBER_ADD
Authorization: Bearer <project-token>
{
  "teamId": "team_xyz",
  "userId": "user_abc",
  "roleIds": ["role_789"]
}
```

**TEAM_MEMBER_REMOVE**

```typescript
// Remove member from team
POST /my-project/mcp/tools/TEAM_MEMBER_REMOVE
Authorization: Bearer <project-token>
{
  "teamId": "team_xyz",
  "userId": "user_abc"
}
```

**TEAM_MEMBER_UPDATE_ROLES**

```typescript
// Update member roles
POST /my-project/mcp/tools/TEAM_MEMBER_UPDATE_ROLES
Authorization: Bearer <project-token>
{
  "teamId": "team_xyz",
  "userId": "user_abc",
  "roleIds": ["role_789", "role_101"]
}
```

#### Audit & Monitoring (Project-Scoped: `/:project/mcp`)

**AUDIT_QUERY**

```typescript
// Query audit logs
POST /my-project/mcp/tools/AUDIT_QUERY
Authorization: Bearer <project-token>
{
  "userId": "user_abc", // Optional filter
  "connectionId": "conn_abc123", // Optional filter
  "toolName": "SEND_EMAIL", // Optional filter
  "startDate": "2025-01-01T00:00:00Z",
  "endDate": "2025-01-31T23:59:59Z",
  "limit": 100,
  "offset": 0
}
// Returns: { logs: [...], total: 1234 }
```

**AUDIT_STATS**

```typescript
// Get usage statistics
POST /my-project/mcp/tools/AUDIT_STATS
Authorization: Bearer <project-token>
{
  "groupBy": "tool", // or "connection", "user", "day"
  "startDate": "2025-01-01T00:00:00Z",
  "endDate": "2025-01-31T23:59:59Z"
}
// Returns: { stats: { SEND_EMAIL: 450, READ_INBOX: 1200, ... } }
```

### The MCP Mesh Proxy API

**Core Concept:**

The MCP Mesh Proxy is the heart of the system. It acts as a secure intermediary that:

1. Accepts requests with project-scoped JWT tokens (with `aud` claim)
2. Validates tokens and checks policies
3. Replaces Mesh tokens with actual service credentials
4. Proxies requests to target MCP services
5. Logs all activity for auditing

**How It Works:**

#### Step 1: Create a Project

```bash
POST /mcp/tools/PROJECT_CREATE
Authorization: Bearer <session-token>
Content-Type: application/json

{
  "name": "My Project",
  "slug": "my-project"
}

# Response:
{
  "id": "proj_abc123",
  "slug": "my-project",
  "name": "My Project"
}
```

#### Step 2: Register an MCP Connection

```bash
POST /my-project/mcp/tools/CONNECTION_CREATE
Authorization: Bearer <project-token with aud: "my-project">
Content-Type: application/json

{
  "name": "Team Gmail",
  "description": "Gmail integration for the team",
  "connection": {
    "type": "HTTP",
    "url": "https://mcp.gmail.com/mcp",
    "token": "gmail-secret-token-XPTO"
  }
}

# Response:
{
  "id": "conn_abc123",
  "name": "Team Gmail",
  "status": "active"
}
```

The Mesh encrypts and stores `gmail-secret-token-XPTO` securely within the project namespace.

#### Step 3: Create Policy and Access Token

```bash
# Create policy
POST /my-project/mcp/tools/POLICY_CREATE
Authorization: Bearer <project-token>
Content-Type: application/json

{
  "name": "Gmail Send Only",
  "statements": [
    {
      "effect": "allow",
      "resource": "SEND_EMAIL",
      "matchCondition": {
        "resource": "is_connection",
        "connectionId": "conn_abc123"
      }
    }
  ]
}

# Response:
{
  "id": "policy_123",
  "name": "Gmail Send Only"
}

# Create access token
POST /my-project/mcp/tools/TOKEN_CREATE
Authorization: Bearer <project-token>
Content-Type: application/json

{
  "name": "Engineering Team Gmail Access",
  "policyIds": ["policy_123"],
  "expiresIn": "90d"
}

# Response:
{
  "id": "token_xyz789",
  "token": "mesh_eyJhbGciOiJIUzI1NiIs...",
  "expiresAt": "2025-01-26T00:00:00Z"
}
```

The `mesh_eyJhbGciOiJIUzI1NiIs...` token contains:

- `aud`: "my-project" (project slug)
- `projectId`: "proj_abc123"
- `tokenId`: "token_xyz789"
- `policyIds`: ["policy_123"]
- Standard claims: `sub`, `iss`, `iat`, `exp`

#### Step 4: Use the Proxy API

```bash
POST /my-project/mcp/:connectionId
Authorization: Bearer mesh_eyJhbGciOiJIUzI1NiIs...
Content-Type: application/json

# Example: Call SEND_EMAIL tool via proxy
POST /my-project/mcp/conn_abc123
{
  "tool": "SEND_EMAIL",
  "arguments": {
    "to": "customer@example.com",
    "subject": "Welcome!",
    "body": "Thanks for signing up"
  }
}
```

**Behind the Scenes:**

1. Mesh validates the JWT token `mesh_eyJhbGciOiJIUzI1NiIs...`
2. Verifies `aud` claim matches project slug from URL path (`my-project`)
3. Extracts `tokenId` and `policyIds` → evaluates policies
4. Checks if `SEND_EMAIL` tool is allowed for `conn_abc123` per policy
5. Retrieves connection config and decrypts the Gmail token: `gmail-secret-token-XPTO`
6. Proxies the request to `https://mcp.gmail.com/mcp`:

   ```bash
   POST https://mcp.gmail.com/mcp
   Authorization: Bearer gmail-secret-token-XPTO
   Content-Type: application/json
   
   {
     "tool": "SEND_EMAIL",
     "arguments": { 
       "to": "customer@example.com",
       "subject": "Welcome!",
       "body": "Thanks for signing up"
     }
   }
   ```

7. Returns the response to the client
8. Logs the request in the audit log (project-scoped)

**Proxy API Specification:**

```typescript
// Proxy endpoint (project-scoped)
POST /:projectSlug/mcp/:connectionId

// Headers
Authorization: Bearer <mesh-issued-jwt with aud: projectSlug>
Content-Type: application/json

// Request Body (standard MCP format)
{
  "tool": string,
  "arguments": object
}

// Response (proxied from actual MCP service)
{
  "result": any,
  "error"?: string
}

// Error Responses
401 Unauthorized       // Invalid or expired token, or aud mismatch
403 Forbidden          // Tool not allowed by policy
404 Not Found          // Connection or project doesn't exist
500 Internal Error     // Proxy or downstream error
```

**Token Structure (JWT Claims):**

```typescript
interface MeshTokenPayload {
  // Standard JWT claims (RFC 7519)
  sub: string;           // Subject: Token ID or User ID
  iss: string;           // Issuer: Mesh instance base URL (e.g., "https://mesh.example.com") - REQUIRED
  iat: number;           // Issued at: Unix timestamp
  exp: number;           // Expiration: Unix timestamp - REQUIRED
  nbf: number;           // Not before: Unix timestamp (prevents premature use) - REQUIRED
  aud: string;           // Audience: Stable immutable identifier - REQUIRED
                         //   - Workspace token: "workspace" (database-level, projectId is null)
                         //   - Project token: "project:proj_abc123" (namespace-level)
  jti: string;           // JWT ID: Unique identifier for revocation tracking - REQUIRED
  
  // Mesh-specific claims (organization is implicit via database connection)
  projectId?: string;       // Project ID (e.g., "proj_abc123") - null for workspace tokens
  projectSlug?: string;     // Project slug (e.g., "my-project") - null for workspace tokens
  userId?: string;          // User ID (if user session token)
  apiKeyId?: string;        // API Key ID (if API key token)
  role?: string;            // User role (e.g., "admin", "user", "developer")
  permissions?: Permission; // Better Auth permissions: { connectionId: ["tool1", "tool2"] }
}
```

**Security Features:**

1. **Credential Isolation**: Original service tokens never leave the Mesh
2. **Encryption at Rest**: All credentials encrypted using AES-256-GCM
3. **Policy Enforcement**: Tools are checked before proxying
4. **Audit Trail**: Every request logged with full context
5. **Token Rotation**: Mesh tokens can be rotated without touching service credentials
6. **Instant Revocation**: Disable a Mesh token immediately without API calls to services

### Self-Hosting Guide

**Prerequisites:**

- Bun runtime (for local deployment), OR
- Docker (for containerized deployment)

That's it! No database setup required.

**Deployment Options:**

**Option 1: Standalone Binary (Recommended for Getting Started)**

```bash
# Download the latest release
curl -L https://github.com/your-org/mcp-mesh/releases/latest/download/mcp-mesh-linux -o mcp-mesh
chmod +x mcp-mesh

# Run with zero configuration
./mcp-mesh start

# The server starts immediately at http://localhost:3000
# SQLite database is automatically created at ./data/mesh.db
```

**Option 2: From Source**

```bash
# Clone and install
git clone https://github.com/your-org/mcp-mesh.git
cd mcp-mesh
bun install

# Run
bun run start
```

**Option 3: Docker (SQLite - Zero Config)**

```yaml
# docker-compose.yml
version: '3.8'

services:
  mesh:
    image: mcp-mesh/server:latest
    ports:
      - "3000:3000"
    volumes:
      - ./data:/app/data           # Persist SQLite database
      - ./auth-config.json:/app/auth-config.json  # Optional auth config
```

```bash
docker-compose up -d
```

**Option 4: Docker with PostgreSQL (Optional - for scale)**

Only needed if you expect high concurrent usage or want to run multiple Mesh instances.

```yaml
# docker-compose.yml
version: '3.8'

services:
  postgres:
    image: postgres:16
    environment:
      POSTGRES_DB: mcp_mesh
      POSTGRES_USER: mesh
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data

  mesh:
    image: mcp-mesh/server:latest
    depends_on:
      - postgres
    environment:
      DATABASE_URL: postgresql://mesh:${DB_PASSWORD}@postgres:5432/mcp_mesh
    ports:
      - "3000:3000"
    volumes:
      - ./auth-config.json:/app/auth-config.json  # Optional auth config

volumes:
  postgres_data:
```

**Environment Variables:**

MCP Mesh is designed with minimal configuration. Only **one** environment variable is supported:

```bash
# Database (optional - defaults to SQLite at ./data/mesh.db)
DATABASE_URL=postgresql://user:pass@host:5432/dbname
```

That's it! All other configuration is done via the optional `auth-config.json` file.

**Authentication Configuration** (`auth-config.json`):

Instead of environment variables, authentication is configured via an optional JSON file:

```json
{
  "emailAndPassword": {
    "enabled": true
  },
  "socialProviders": {
    "google": {
      "clientId": "your-google-client-id",
      "clientSecret": "your-google-client-secret"
    },
    "github": {
      "clientId": "your-github-client-id",
      "clientSecret": "your-github-client-secret"
    }
  },
  "saml": {
    "enabled": true,
    "providers": [
      {
        "name": "Okta",
        "entryPoint": "https://your-org.okta.com/app/...",
        "issuer": "http://www.okta.com/...",
        "cert": "-----BEGIN CERTIFICATE-----..."
      }
    ]
  }
}
```

**Production Considerations:**

1. **SSL/TLS**: Always use HTTPS in production (use a reverse proxy like Caddy or nginx)
2. **Database Backups**:
   - SQLite: Simple file-based backups (`cp data/mesh.db backups/mesh-$(date +%Y%m%d).db`)
   - PostgreSQL: Use `pg_dump` or automated backup solutions
3. **Secret Management**:
   - Secrets (JWT, encryption keys) are auto-generated on first run and stored in the database
   - Protect the `auth-config.json` file as it contains OAuth/SAML secrets
   - Use environment variable substitution in `auth-config.json` if needed for secret management
4. **Monitoring**: Set up health checks and alerting
5. **Rate Limiting**: Implement rate limits on proxy endpoints via reverse proxy
6. **Logging**: Configure structured logging for audit compliance
7. **Scaling**:
   - Single instance: SQLite is perfect
   - Multiple instances: Migrate to PostgreSQL with load balancer
8. **Project Isolation**: Each project operates in its own namespace with isolated credentials

---

## Roadmap

### Phase 1: Core Infrastructure (MVP)

- [x] Database schema design
- [x] Project/namespace architecture
- [ ] Authentication system (Better Auth with JSON config)
- [ ] Project management tools
- [ ] Connection management tools
- [ ] Policy and role management tools
- [ ] Token issuance and validation with `aud` claim
- [ ] Basic proxy implementation (`/:project/mcp/:connectionId`)
- [ ] Audit logging (project-scoped)

### Phase 2: Security & Access Control

- [ ] Fine-grained policy engine with statements
- [ ] Role-based access control
- [ ] Team and member management
- [ ] Credential encryption (AES-256-GCM)
- [ ] Token revocation
- [ ] Rate limiting per project

### Phase 3: Developer Experience

- [ ] CLI tool for project and connection management
- [ ] TypeScript/Python SDKs
- [ ] Web-based admin UI
- [ ] Connection testing tools
- [ ] Interactive documentation
- [ ] Project templates

### Phase 4: Advanced Features

- [ ] Tool composition across connections
- [ ] MCP dependency resolution
- [ ] Response caching layer
- [ ] Webhook support for events
- [ ] Metrics and analytics dashboard (per project)
- [ ] Multi-region deployment support

---

## Contributing

We welcome contributions! Please see our [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines.

## License

MCP Mesh is open-source software licensed under the [MIT License](./LICENSE).
